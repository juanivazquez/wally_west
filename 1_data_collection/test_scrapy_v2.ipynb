{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62e0d8ed-9ed2-4a3d-9821-e93837d8a71b",
   "metadata": {},
   "source": [
    "Fuentes:\n",
    "    https://www.youtube.com/watch?v=mBoX_JCKZTE&t=31s\n",
    "    \n",
    "    https://www.mikulskibartosz.name/how-to-scrape-a-single-web-page-using-scrapy-in-jupyter-notebook/\n",
    "    \n",
    "    https://www.jitsejan.com/using-scrapy-in-jupyter-notebook\n",
    "    \n",
    "Data:\n",
    "\n",
    "    https://www.boletinoficial.gob.ar/detalleAviso/segunda/A0000001/20230503 (boletín digital)\n",
    "    https://www.boletinoficial.gob.ar/detalleAviso/segunda/H681119/19830527 (boletín impreso/pdf)\n",
    "    https://timeline.boletinoficial.gob.ar/ (búsqueda)\n",
    "    https://www.boletinoficial.gob.ar/busquedaAvanzada/segunda\n",
    "    \n",
    "    scrapping boletin oficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12dc0532-5727-4be9-b3d4-76db9856bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "# scrape webpage\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "# Reactor restart\n",
    "from crochet import setup, wait_for\n",
    "\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir('C:\\\\Users\\\\juani\\\\Documents\\\\3_My_Jupiter_Notebooks\\\\5_Galicia\\\\2_LLMs\\\\venv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057769c4-d09d-483b-adc9-83744f7684c2",
   "metadata": {},
   "source": [
    "# CASO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02dac8d2-6f5d-4542-8aed-e13be69d0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup()\n",
    "class QuotesToCsv(scrapy.Spider):\n",
    "    \"\"\"scrape first line of  quotes from `wikiquote` by \n",
    "    Maynard James Keenan and save to json file\"\"\"\n",
    "    name = \"MJKQuotesToCsv\"\n",
    "    start_urls = [\n",
    "        'https://en.wikiquote.org/wiki/Maynard_James_Keenan',\n",
    "    ]\n",
    "    custom_settings = {\n",
    "        'ITEM_PIPELINES': {\n",
    "            '__main__.ExtractFirstLine': 1\n",
    "        },\n",
    "        'FEEDS': {\n",
    "            'quotes.csv': {\n",
    "                'format': 'csv',\n",
    "                'overwrite': True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def parse(self, response):\n",
    "        \"\"\"parse data from urls\"\"\"\n",
    "        for quote in response.css('div.mw-parser-output > ul > li'):\n",
    "            yield {'quote': quote.extract()}\n",
    "\n",
    "\n",
    "class ExtractFirstLine(object):\n",
    "    def process_item(self, item, spider):\n",
    "        \"\"\"text processing\"\"\"\n",
    "        lines = dict(item)[\"quote\"].splitlines()\n",
    "        first_line = self.__remove_html_tags__(lines[0])\n",
    "\n",
    "        return {'quote': first_line}\n",
    "\n",
    "    def __remove_html_tags__(self, text):\n",
    "        \"\"\"remove html tags from string\"\"\"\n",
    "        html_tags = re.compile('<.*?>')\n",
    "        return re.sub(html_tags, '', text)\n",
    "\n",
    "@wait_for(10)\n",
    "def run_spider():\n",
    "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(QuotesToCsv)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c7d841-9487-4b7e-ab70-040edc16895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@wait_for(10)\n",
    "def run_spider(charlotte):\n",
    "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(charlotte)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc96c491-49c6-4fc3-afc6-0c58e3ae2a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_spider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b9d4e4-821c-44ca-9bce-8b4708030a1d",
   "metadata": {},
   "source": [
    "# CASO BOLETIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd12f0c5-ddfd-4d92-b5e7-c3b1c2062fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 14:07:52 [py.warnings] WARNING: C:\\Users\\juani\\anaconda3\\envs\\llm\\lib\\site-packages\\scrapy\\utils\\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2023-05-04 14:07:52 [scrapy.extensions.telnet] INFO: Telnet Password: 992650a3c94d5367\n",
      "2023-05-04 14:07:52 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2023-05-04 14:07:52 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2023-05-04 14:07:52 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2023-05-04 14:07:52 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2023-05-04 14:07:52 [scrapy.core.engine] INFO: Spider opened\n",
      "2023-05-04 14:07:52 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2023-05-04 14:07:52 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Deferred at 0x28495378b80>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BoletinSpider(scrapy.Spider):\n",
    "    name = \"boletin\"\n",
    "    start_urls = [\n",
    "        \"https://www.boletinoficial.gob.ar/detalleAviso/segunda/A1194898/20230503\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        item = {}        \n",
    "        item[\"title\"] = response.xpath('//title/text()').get()\n",
    "        item[\"css\"] = response.css('div.avisoContenido article div#detalleAviso div#tituloDetalleAviso + div#cuerpoDetalleAviso p::text').get()\n",
    "        \n",
    "        print('title',item[\"title\"])\n",
    "        print('+css',item[\"css\"])\n",
    "        \n",
    "        yield {\"content\": item}\n",
    "\n",
    "def run_spider_BoletinSpider():\n",
    "    \"\"\"run spider with BoletinSpider\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(BoletinSpider)\n",
    "    return d\n",
    "run_spider_BoletinSpider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfdcb81a-b7f2-4349-8aa8-64fea9bb8ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Deferred at 0x21782ff2aa0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scrapy\n",
    "\n",
    "class MySpider(scrapy.Spider):\n",
    "    name = \"my_spider\"\n",
    "    start_urls = []\n",
    "    \n",
    "    def start_requests(self):\n",
    "        base_url = \"https://www.boletinoficial.gob.ar/detalleAviso/segunda\"\n",
    "        a_values = [\"A1194898\", \"A1234567\", \"A9876543\"] # List of different values for A\n",
    "        b_values = [\"20230503\", \"20230430\", \"20230401\"] # List of different values for B\n",
    "        for a in a_values:\n",
    "            for b in b_values:\n",
    "                url = f\"{base_url}/{a}/{b}\"\n",
    "                yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        # Extract data from the response object\n",
    "        # For example:\n",
    "        content = response.css('div.avisoContenido article div#cuerpoDetalleAviso p::text').get()\n",
    "        yield {\"content\": content}\n",
    "        \n",
    "        \n",
    "def run_spider_BoletinSpider():\n",
    "    \"\"\"run spider with BoletinSpider\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(MySpider)\n",
    "    return d\n",
    "\n",
    "\n",
    "run_spider_BoletinSpider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a189dee-ea9e-4969-9473-5fc04906e985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juani\\anaconda3\\envs\\llm\\lib\\site-packages\\scrapy\\utils\\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n"
     ]
    }
   ],
   "source": [
    "# Please adapt the following code written in python using the libraries scrapy and crochet in order to save to a csv the scraped content of the website:\n",
    "\n",
    "class BoletinSpider(scrapy.Spider):\n",
    "    name = \"boletin\"\n",
    "    start_urls = [\n",
    "        \"https://www.boletinoficial.gob.ar/detalleAviso/segunda/A1194898/20230503\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        item = {}        \n",
    "        title = response.xpath('//title/text()').get()\n",
    "        content = response.css('div.avisoContenido article div#detalleAviso div#tituloDetalleAviso + div#cuerpoDetalleAviso p::text').get()\n",
    "        # content = response.css('div.avisoContenido article div#cuerpoDetalleAviso p::text').get()\n",
    "        yield {\"title\": title, 'content':content}\n",
    "\n",
    "def run_spider_BoletinSpider():\n",
    "    \"\"\"run spider with BoletinSpider\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(BoletinSpider)\n",
    "    return d\n",
    "\n",
    "\n",
    "test = run_spider_BoletinSpider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bdc5ee0-e4fb-4159-993c-e5d74eb6c117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Deferred at 0x21ca875d330>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ea747d-8f15-40bd-b731-199a8e5431f1",
   "metadata": {},
   "source": [
    "# CASO BOLETIN CON OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b6b50b-2678-42c1-8321-d2f16af4982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup()\n",
    "class BoletinToCsv(scrapy.Spider):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    name = \"BoletinToCsv\"\n",
    "    start_urls = [\n",
    "        'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A1194898/20230503',\n",
    "    ]\n",
    "    custom_settings = {\n",
    "        'ITEM_PIPELINES': {\n",
    "            '__main__.ExtractFirstLine': 1\n",
    "        },\n",
    "        'FEEDS': {\n",
    "            'quotes.csv': {\n",
    "                'format': 'csv',\n",
    "                'overwrite': True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def parse(self, response):\n",
    "        \"\"\"parse data from urls\"\"\"\n",
    "        item = {}\n",
    "        item[\"title\"] = response.xpath('//title/text()').get()\n",
    "        item[\"css\"] = response.css('div.avisoContenido article div#detalleAviso div#tituloDetalleAviso + div#cuerpoDetalleAviso p::text').get()\n",
    "        yield item\n",
    "\n",
    "\n",
    "class ExtractFirstLine(object):\n",
    "    def process_item(self, item, spider):\n",
    "        \"\"\"text processing\"\"\"\n",
    "        lines = dict(item)[\"quote\"].splitlines()\n",
    "        first_line = self.__remove_html_tags__(lines[0])\n",
    "\n",
    "        return {'quote': first_line}\n",
    "\n",
    "    def __remove_html_tags__(self, text):\n",
    "        \"\"\"remove html tags from string\"\"\"\n",
    "        html_tags = re.compile('<.*?>')\n",
    "        return re.sub(html_tags, '', text)\n",
    "\n",
    "@wait_for(10)\n",
    "def run_spider():\n",
    "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(QuotesToCsv)\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "class BoletinSpider(scrapy.Spider):\n",
    "    name = \"boletin\"\n",
    "    start_urls = [\n",
    "        \"https://www.boletinoficial.gob.ar/detalleAviso/segunda/A1194898/20230503\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        item = {}\n",
    "        # title = response.xpath('//title/text()').get()\n",
    "        item[\"title\"] = response.xpath('//title/text()').get()\n",
    "        # item[\"body\"] = response.xpath('//div[@class=\"avisoContenido\"]/article/div[@id=\"cuerpoDetalleAviso\"]/p/text()').get()\n",
    "        item[\"css\"] = response.css('div.avisoContenido article div#detalleAviso div#tituloDetalleAviso + div#cuerpoDetalleAviso p::text').get()\n",
    "\n",
    "        # item[\"body\"] = response.xpath('//div[@id=\"tituloDetalleAviso\"]').get()\n",
    "        # print(item[\"title\"])\n",
    "        print('title',item[\"title\"])\n",
    "        print('css',item[\"css\"])\n",
    "\n",
    "        # for k,v in item.items():\n",
    "        #     print(k,v)\n",
    "        \n",
    "        \n",
    "        # product = response.css(\"div.product_main\")\n",
    "        # item[\"title\"] = product.css(\"h1 ::text\").extract_first()\n",
    "        # item['category'] = response.xpath(\n",
    "        #     \"//ul[@class='breadcrumb']/li[@class='active']/preceding-sibling::li[1]/a/text()\"\n",
    "        # ).extract_first()\n",
    "        # item['description'] = response.xpath(\n",
    "        #     \"//div[@id='product_description']/following-sibling::p/text()\"\n",
    "        # ).extract_first()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        return item\n",
    "def run_spider_BoletinSpider():\n",
    "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(BoletinSpider)\n",
    "    return d\n",
    "test = run_spider_BoletinSpider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e9a5c2-78a3-4d57-b9aa-875d60b955e9",
   "metadata": {},
   "source": [
    "# CASO 2 tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8304fece-cd60-4a1a-909c-8195310b227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup()\n",
    "\n",
    "class BooksSpider(scrapy.Spider):\n",
    "    name = 'books'\n",
    "\n",
    "    def start_requests(self):\n",
    "        url = 'https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'\n",
    "        yield scrapy.Request(url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        item = {}\n",
    "        product = response.css(\"div.product_main\")\n",
    "        item[\"title\"] = product.css(\"h1 ::text\").extract_first()\n",
    "        item['category'] = response.xpath(\n",
    "            \"//ul[@class='breadcrumb']/li[@class='active']/preceding-sibling::li[1]/a/text()\"\n",
    "        ).extract_first()\n",
    "        item['description'] = response.xpath(\n",
    "            \"//div[@id='product_description']/following-sibling::p/text()\"\n",
    "        ).extract_first()\n",
    "        item['price'] = response.css('p.price_color ::text').extract_first()\n",
    "        yield item\n",
    "@wait_for(10)       \n",
    "def run_spider2():\n",
    "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(BooksSpider)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "006c3e59-0439-4a6b-bfb6-f93ecb67792e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Request' object has no attribute 'css'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m product \u001b[38;5;241m=\u001b[39m  scrapy\u001b[38;5;241m.\u001b[39mRequest(url)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mproduct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcss\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv.product_main\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Request' object has no attribute 'css'"
     ]
    }
   ],
   "source": [
    "url = 'https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'\n",
    "product =  scrapy.Request(url)\n",
    "product.css(\"div.product_main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0ced7a-7c76-408b-b2fc-8f2ab8db23d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# caso nuevo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6309c08-0ebe-46f6-b3c5-aeee4dcce981",
   "metadata": {},
   "source": [
    "https://www.jitsejan.com/using-scrapy-in-jupyter-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f0eebea-956d-4e1c-9156-9e467a30ce23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Settings for notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# Show Python version\n",
    "import platform\n",
    "platform.python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a9c7210-4b33-458d-81d4-5c751ca625f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import scrapy\n",
    "except:\n",
    "    !pip install scrapy\n",
    "    import scrapy\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dd596cf-b18e-45b5-8d8a-e672c79c90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "905a4373-16f4-4db6-b25f-829c8ece8074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('quoteresult.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8026f9cc-8720-4c90-9c76-f0cc5b005cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'http://quotes.toscrape.com/page/1/',\n",
    "        'http://quotes.toscrape.com/page/2/',\n",
    "    ]\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'quoteresult.json'                        # Used for pipeline 2\n",
    "    }\n",
    "    \n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').extract_first(),\n",
    "                'author': quote.css('span small::text').extract_first(),\n",
    "                'tags': quote.css('div.tags a.tag::text').extract(),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f8f24d9-8fdd-4353-807d-3bea7137ea26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 12:00:34 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scrapybot)\n",
      "2023-05-04 12:00:34 [scrapy.utils.log] INFO: Versions: lxml 4.9.2.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.1, Twisted 22.10.0, Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:32:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 23.1.1 (OpenSSL 3.1.0 14 Mar 2023), cryptography 40.0.1, Platform Windows-10-10.0.19044-SP0\n",
      "2023-05-04 12:00:34 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 30,\n",
      " 'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}\n",
      "2023-05-04 12:00:34 [py.warnings] WARNING: C:\\Users\\juani\\anaconda3\\envs\\llm\\lib\\site-packages\\scrapy\\utils\\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2023-05-04 12:00:34 [py.warnings] WARNING: C:\\Users\\juani\\anaconda3\\envs\\llm\\lib\\site-packages\\scrapy\\extensions\\feedexport.py:315: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details\n",
      "  exporter = cls(crawler)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Deferred at 0x28493cdc760>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 12:00:35 [py.warnings] WARNING: C:\\Users\\juani\\anaconda3\\envs\\llm\\lib\\site-packages\\scrapy\\selector\\unified.py:83: UserWarning: Selector got both text and root, root is being ignored.\n",
      "  super().__init__(text=text, type=st, root=root, **kwargs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
    "})\n",
    "\n",
    "process.crawl(QuotesSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bf8f670-f86f-43ab-b1ca-9b706480e679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quoteresult.jl\n",
      "quoteresult.json\n"
     ]
    }
   ],
   "source": [
    "!ls quoteresult.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6dadb361-bbc0-4ddb-8666-f67c5b04d6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\": \"\\u201cA woman is like a tea bag; you never know how strong it is until it's in hot water.\\u201d\", \"author\": \"Eleanor Roosevelt\", \"tags\": [\"misattributed-eleanor-roosevelt\"]}\n",
      "{\"text\": \"\\u201cA day without sunshine is like, you know, night.\\u201d\", \"author\": \"Steve Martin\", \"tags\": [\"humor\", \"obvious\", \"simile\"]}\n"
     ]
    }
   ],
   "source": [
    "!tail -n 2 quoteresult.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30394b95-9fb5-4c28-b87e-45cfb2823a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\": \"\\u201cA day without sunshine is like, you know, night.\\u201d\", \"author\": \"Steve Martin\", \"tags\": [\"humor\", \"obvious\", \"simile\"]}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!tail -n 2 quoteresult.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5dce401-c54c-4596-84ef-73c4d1d971c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“This life is what you make it. No matter what...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>[friends, heartbreak, inspirational, life, lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“It takes a great deal of bravery to stand up ...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>[courage, friends]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“If you can't explain it to a six year old, yo...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[simplicity, understand]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“You may not be her first, her last, or her on...</td>\n",
       "      <td>Bob Marley</td>\n",
       "      <td>[love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“I like nonsense, it wakes up the brain cells....</td>\n",
       "      <td>Dr. Seuss</td>\n",
       "      <td>[fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“I may not have gone where I intended to go, b...</td>\n",
       "      <td>Douglas Adams</td>\n",
       "      <td>[life, navigation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>“The opposite of love is not hate, it's indiff...</td>\n",
       "      <td>Elie Wiesel</td>\n",
       "      <td>[activism, apathy, hate, indifference, inspira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>“It is not a lack of love, but a lack of frien...</td>\n",
       "      <td>Friedrich Nietzsche</td>\n",
       "      <td>[friendship, lack-of-friendship, lack-of-love,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>“Good friends, good books, and a sleepy consci...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>[books, contentment, friends, friendship, life]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>“Life is what happens to us while we are makin...</td>\n",
       "      <td>Allen Saunders</td>\n",
       "      <td>[fate, life, misattributed-john-lennon, planni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>“The world as we have created it is a process ...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[change, deep-thoughts, thinking, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>“It is our choices, Harry, that show what we t...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>[abilities, choices]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>“There are only two ways to live your life. On...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[inspirational, life, live, miracle, miracles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>[aliteracy, books, classic, humor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>[be-yourself, inspirational]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>“Try not to become a man of success. Rather be...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[adulthood, success, value]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>“It is better to be hated for what you are tha...</td>\n",
       "      <td>André Gide</td>\n",
       "      <td>[life, love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>“I have not failed. I've just found 10,000 way...</td>\n",
       "      <td>Thomas A. Edison</td>\n",
       "      <td>[edison, failure, inspirational, paraphrased]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>“A woman is like a tea bag; you never know how...</td>\n",
       "      <td>Eleanor Roosevelt</td>\n",
       "      <td>[misattributed-eleanor-roosevelt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“A day without sunshine is like, you know, nig...</td>\n",
       "      <td>Steve Martin</td>\n",
       "      <td>[humor, obvious, simile]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text               author   \n",
       "0   “This life is what you make it. No matter what...       Marilyn Monroe  \\\n",
       "1   “It takes a great deal of bravery to stand up ...         J.K. Rowling   \n",
       "2   “If you can't explain it to a six year old, yo...      Albert Einstein   \n",
       "3   “You may not be her first, her last, or her on...           Bob Marley   \n",
       "4   “I like nonsense, it wakes up the brain cells....            Dr. Seuss   \n",
       "5   “I may not have gone where I intended to go, b...        Douglas Adams   \n",
       "6   “The opposite of love is not hate, it's indiff...          Elie Wiesel   \n",
       "7   “It is not a lack of love, but a lack of frien...  Friedrich Nietzsche   \n",
       "8   “Good friends, good books, and a sleepy consci...           Mark Twain   \n",
       "9   “Life is what happens to us while we are makin...       Allen Saunders   \n",
       "10  “The world as we have created it is a process ...      Albert Einstein   \n",
       "11  “It is our choices, Harry, that show what we t...         J.K. Rowling   \n",
       "12  “There are only two ways to live your life. On...      Albert Einstein   \n",
       "13  “The person, be it gentleman or lady, who has ...          Jane Austen   \n",
       "14  “Imperfection is beauty, madness is genius and...       Marilyn Monroe   \n",
       "15  “Try not to become a man of success. Rather be...      Albert Einstein   \n",
       "16  “It is better to be hated for what you are tha...           André Gide   \n",
       "17  “I have not failed. I've just found 10,000 way...     Thomas A. Edison   \n",
       "18  “A woman is like a tea bag; you never know how...    Eleanor Roosevelt   \n",
       "19  “A day without sunshine is like, you know, nig...         Steve Martin   \n",
       "\n",
       "                                                 tags  \n",
       "0   [friends, heartbreak, inspirational, life, lov...  \n",
       "1                                  [courage, friends]  \n",
       "2                            [simplicity, understand]  \n",
       "3                                              [love]  \n",
       "4                                           [fantasy]  \n",
       "5                                  [life, navigation]  \n",
       "6   [activism, apathy, hate, indifference, inspira...  \n",
       "7   [friendship, lack-of-friendship, lack-of-love,...  \n",
       "8     [books, contentment, friends, friendship, life]  \n",
       "9   [fate, life, misattributed-john-lennon, planni...  \n",
       "10           [change, deep-thoughts, thinking, world]  \n",
       "11                               [abilities, choices]  \n",
       "12     [inspirational, life, live, miracle, miracles]  \n",
       "13                 [aliteracy, books, classic, humor]  \n",
       "14                       [be-yourself, inspirational]  \n",
       "15                        [adulthood, success, value]  \n",
       "16                                       [life, love]  \n",
       "17      [edison, failure, inspirational, paraphrased]  \n",
       "18                  [misattributed-eleanor-roosevelt]  \n",
       "19                           [humor, obvious, simile]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfjson = pd.read_json('quoteresult.json')\n",
    "dfjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88eb4e33-f6e4-4ce0-a8c1-ca0c550b47a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“This life is what you make it. No matter what...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>[friends, heartbreak, inspirational, life, lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“It takes a great deal of bravery to stand up ...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>[courage, friends]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“If you can't explain it to a six year old, yo...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[simplicity, understand]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“You may not be her first, her last, or her on...</td>\n",
       "      <td>Bob Marley</td>\n",
       "      <td>[love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“I like nonsense, it wakes up the brain cells....</td>\n",
       "      <td>Dr. Seuss</td>\n",
       "      <td>[fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“I may not have gone where I intended to go, b...</td>\n",
       "      <td>Douglas Adams</td>\n",
       "      <td>[life, navigation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>“The opposite of love is not hate, it's indiff...</td>\n",
       "      <td>Elie Wiesel</td>\n",
       "      <td>[activism, apathy, hate, indifference, inspira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>“It is not a lack of love, but a lack of frien...</td>\n",
       "      <td>Friedrich Nietzsche</td>\n",
       "      <td>[friendship, lack-of-friendship, lack-of-love,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>“Good friends, good books, and a sleepy consci...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>[books, contentment, friends, friendship, life]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>“Life is what happens to us while we are makin...</td>\n",
       "      <td>Allen Saunders</td>\n",
       "      <td>[fate, life, misattributed-john-lennon, planni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>“The world as we have created it is a process ...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[change, deep-thoughts, thinking, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>“It is our choices, Harry, that show what we t...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>[abilities, choices]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>“There are only two ways to live your life. On...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[inspirational, life, live, miracle, miracles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>[aliteracy, books, classic, humor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>[be-yourself, inspirational]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>“Try not to become a man of success. Rather be...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[adulthood, success, value]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>“It is better to be hated for what you are tha...</td>\n",
       "      <td>André Gide</td>\n",
       "      <td>[life, love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>“I have not failed. I've just found 10,000 way...</td>\n",
       "      <td>Thomas A. Edison</td>\n",
       "      <td>[edison, failure, inspirational, paraphrased]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>“A woman is like a tea bag; you never know how...</td>\n",
       "      <td>Eleanor Roosevelt</td>\n",
       "      <td>[misattributed-eleanor-roosevelt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“A day without sunshine is like, you know, nig...</td>\n",
       "      <td>Steve Martin</td>\n",
       "      <td>[humor, obvious, simile]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text               author   \n",
       "0   “This life is what you make it. No matter what...       Marilyn Monroe  \\\n",
       "1   “It takes a great deal of bravery to stand up ...         J.K. Rowling   \n",
       "2   “If you can't explain it to a six year old, yo...      Albert Einstein   \n",
       "3   “You may not be her first, her last, or her on...           Bob Marley   \n",
       "4   “I like nonsense, it wakes up the brain cells....            Dr. Seuss   \n",
       "5   “I may not have gone where I intended to go, b...        Douglas Adams   \n",
       "6   “The opposite of love is not hate, it's indiff...          Elie Wiesel   \n",
       "7   “It is not a lack of love, but a lack of frien...  Friedrich Nietzsche   \n",
       "8   “Good friends, good books, and a sleepy consci...           Mark Twain   \n",
       "9   “Life is what happens to us while we are makin...       Allen Saunders   \n",
       "10  “The world as we have created it is a process ...      Albert Einstein   \n",
       "11  “It is our choices, Harry, that show what we t...         J.K. Rowling   \n",
       "12  “There are only two ways to live your life. On...      Albert Einstein   \n",
       "13  “The person, be it gentleman or lady, who has ...          Jane Austen   \n",
       "14  “Imperfection is beauty, madness is genius and...       Marilyn Monroe   \n",
       "15  “Try not to become a man of success. Rather be...      Albert Einstein   \n",
       "16  “It is better to be hated for what you are tha...           André Gide   \n",
       "17  “I have not failed. I've just found 10,000 way...     Thomas A. Edison   \n",
       "18  “A woman is like a tea bag; you never know how...    Eleanor Roosevelt   \n",
       "19  “A day without sunshine is like, you know, nig...         Steve Martin   \n",
       "\n",
       "                                                 tags  \n",
       "0   [friends, heartbreak, inspirational, life, lov...  \n",
       "1                                  [courage, friends]  \n",
       "2                            [simplicity, understand]  \n",
       "3                                              [love]  \n",
       "4                                           [fantasy]  \n",
       "5                                  [life, navigation]  \n",
       "6   [activism, apathy, hate, indifference, inspira...  \n",
       "7   [friendship, lack-of-friendship, lack-of-love,...  \n",
       "8     [books, contentment, friends, friendship, life]  \n",
       "9   [fate, life, misattributed-john-lennon, planni...  \n",
       "10           [change, deep-thoughts, thinking, world]  \n",
       "11                               [abilities, choices]  \n",
       "12     [inspirational, life, live, miracle, miracles]  \n",
       "13                 [aliteracy, books, classic, humor]  \n",
       "14                       [be-yourself, inspirational]  \n",
       "15                        [adulthood, success, value]  \n",
       "16                                       [life, love]  \n",
       "17      [edison, failure, inspirational, paraphrased]  \n",
       "18                  [misattributed-eleanor-roosevelt]  \n",
       "19                           [humor, obvious, simile]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfjl = pd.read_json('quoteresult.jl', lines=True)\n",
    "dfjl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eabc8937-ad19-49a7-8eb5-f0c064822b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quotejl.pickle\n",
      "quotejson.pickle\n"
     ]
    }
   ],
   "source": [
    "dfjson.to_pickle('quotejson.pickle')\n",
    "dfjl.to_pickle('quotejl.pickle')\n",
    "!ls *pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c572c64-f78e-45d9-b2c3-886f91f6519a",
   "metadata": {},
   "source": [
    "# CASO NUEVO ADAPTADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16974396-66fe-4aaa-ac4b-12991f0a5b6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\juani\\\\Documents\\\\3_My_Jupiter_Notebooks\\\\5_Galicia\\\\2_LLMs\\\\venv'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "from crochet import setup, wait_for\n",
    "\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\juani\\\\Documents\\\\3_My_Jupiter_Notebooks\\\\5_Galicia\\\\2_LLMs\\\\venv')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569f2e29-ff7b-4708-b906-cbb0ec055f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.arange(1,10).tolist()\n",
    "https://www.boletinoficial.gob.ar/detalleAviso/segunda/A0000001/20230503"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57dca07a-0527-474c-9e4a-88ec0579b2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('boletin_resultado.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1dbd6c8-fbe5-42ca-8571-843d44c6fdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A{(7-len(str(i)))*\"0\"}{i}/20230503' for i in np.arange(1,1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "41f93168-e2e5-4b41-9868-846cdc23cded",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ls =  [str(i) for i in np.arange(1,100)]\n",
    "full_ls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A0000001/20230503'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e627e9db-e21d-4ef6-948b-cb507f121158",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup()\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "    'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A0000001/20230503',\n",
    "    'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A0000002/20230503',\n",
    "    'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A0000003/20230503',\n",
    "    'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A0000004/20230503',\n",
    "    ]\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        #'CONCURRENT_REQUESTS_PER_IP':0,\n",
    "        'COOKIES_ENABLED':False,\n",
    "        'DOWNLOAD_DELAY' : 0.25,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'boletin_resultado.json'                        # Used for pipeline 2\n",
    "    }\n",
    "    \n",
    "    def parse(self, response):\n",
    "        text = response.xpath('//title/text()').get()\n",
    "        body = response.css('div.avisoContenido article div#detalleAviso div#tituloDetalleAviso + div#cuerpoDetalleAviso p::text').get()\n",
    "        ref = response.xpath('/html/body/div[4]/div/div[2]/div/div[2]/div/div[2]/div[1]/ol/li[2]/a').get() # ::text\n",
    "        print(text,body,ref)\n",
    "        \n",
    "        yield {\n",
    "                'text': text,\n",
    "                'body': body,\n",
    "                'ref': ref\n",
    "            } \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4953127b-bbc4-42fd-897b-e9efbea20b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOLETIN OFICIAL REPUBLICA ARGENTINA - JUZGADOS NACIONALES \n",
      " EN LO CIVIL\n",
      " N° 42\n",
      "  \n",
      "  El Juzgado Nacional de Primera Instancia N° 42 sito en Uruguay N° 714 - 2do piso – Capital Federal, cita a Alfredo Agapito Vargas a fin de que comparezca a estar a derecho. Publíquese una vez por mes, durante seis meses en el Boletín Oficial. Fdo: Dra. Guisado Paola Mariana. Juez.\n",
      " Buenos Aires, 9 de junio de 2010.\n",
      " Laura Evangelina Filla, secretaria interina.\n",
      "  <a class=\"puntero\" href=\"/seccion/segunda/20230503?rubro=3100\">CITACIONES Y NOTIFICACIONES. CONCURSOS Y QUIEBRAS. OTROS</a>\n",
      "BOLETIN OFICIAL REPUBLICA ARGENTINA None None\n",
      "BOLETIN OFICIAL REPUBLICA ARGENTINA - JUZGADO NACIONAL EN LO \n",
      " CIVIL NRO. 3 \n",
      " SECRETARIA UNICA\n",
      "  El Juzgado Nacional de Primera Instancia en lo Civil Nº 3 sito en Talcahuano 550 piso 6to., cítese a José Inocencio Martínez Dalto a fin de que comparezca a estar a derecho, en los términos del art. 25 de la Ley 14.394.- El presente deberá publicarse una vez por mes por el termino de seis meses en el Boletín Oficial y en el Diario La Ley.\n",
      " Buenos Aires, Julio 5 de 2010.\n",
      " Marcelo Mario Pelayo, secretario.\n",
      "  <a class=\"puntero\" href=\"/seccion/segunda/20230503?rubro=3100\">CITACIONES Y NOTIFICACIONES. CONCURSOS Y QUIEBRAS. OTROS</a>\n",
      "BOLETIN OFICIAL REPUBLICA ARGENTINA - JUZGADOS NACIONALES \n",
      " EN LO CIVIL\n",
      " N° 19\n",
      "  Juzgado Nacional de Primera Instancia en lo Civil Nº 19, Secretaría única, cita a Alberto María Canessa, argentino, L.E. 4.357.989 a fin de que comparezca a estar a derecho en los autos \"Canessa Alberto María s/Ausencia con Presunción de Fallecimiento\" Exp. Nº 33.271/2010. Publíquese una vez por mes durante seis meses en Boletín Oficial.\n",
      " Buenos Aires, 06 de octubre de 2010.\n",
      " María Belén Puebla, secretaria.\n",
      "  <a class=\"puntero\" href=\"/seccion/segunda/20230503?rubro=3100\">CITACIONES Y NOTIFICACIONES. CONCURSOS Y QUIEBRAS. OTROS</a>\n",
      "BOLETIN OFICIAL REPUBLICA ARGENTINA - N° 82\n",
      "  \n",
      "  La Señora Juez Subrogante a cargo del Juzgado Nacional de Primera Instancia en lo Civil Número 82, Dra. Giordanino, Celia Elsa, Secretaría única a mi cargo, en los autos caratulados: \"Quevedo Marcos Santiago s/Adopción\" Expediente Número 77842/2010; a mérito de lo dispuesto por el Art. 17 Ley 18248 publica la solicitud de cambio de apellido de Quevedo Marcos Santiago D.N.I. N° 26.865.715 por el de Marcos Santiago Olivieri con igual número y tipo de documento, pudiendo formularse oposición dentro de los quince días hábiles computados desde la última publicación. Publíquese una vez por mes en el lapso de dos meses en el Boletín Oficial.\n",
      " Buenos Aires, a los 17 días del mes de noviembre de 2010.\n",
      " Laura Cecilia Masi, secretaria int.\n",
      "  <a class=\"puntero\" href=\"/seccion/segunda/20230503?rubro=3100\">CITACIONES Y NOTIFICACIONES. CONCURSOS Y QUIEBRAS. OTROS</a>\n"
     ]
    }
   ],
   "source": [
    "@wait_for(10)\n",
    "def run_spider():\n",
    "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(QuotesSpider)\n",
    "    return d\n",
    "run_spider()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8f3ad62-e4fc-4cf0-9b1a-a719331bbdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfjson = pd.read_json('boletin_resultado.json')\n",
    "# dfjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83be2779-f12d-4d3d-93a1-86b85d5183cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>body</th>\n",
       "      <th>ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOLETIN OFICIAL REPUBLICA ARGENTINA - JUZGADOS...</td>\n",
       "      <td>El Juzgado Nacional de Primera Instancia N° 42...</td>\n",
       "      <td>&lt;a class=\"puntero\" href=\"/seccion/segunda/2023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOLETIN OFICIAL REPUBLICA ARGENTINA - JUZGADO ...</td>\n",
       "      <td>El Juzgado Nacional de Primera Instancia en lo...</td>\n",
       "      <td>&lt;a class=\"puntero\" href=\"/seccion/segunda/2023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOLETIN OFICIAL REPUBLICA ARGENTINA - JUZGADOS...</td>\n",
       "      <td>Juzgado Nacional de Primera Instancia en lo Ci...</td>\n",
       "      <td>&lt;a class=\"puntero\" href=\"/seccion/segunda/2023...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOLETIN OFICIAL REPUBLICA ARGENTINA - N° 82\\n ...</td>\n",
       "      <td>La Señora Juez Subrogante a cargo del Juzgado ...</td>\n",
       "      <td>&lt;a class=\"puntero\" href=\"/seccion/segunda/2023...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   \n",
       "0  BOLETIN OFICIAL REPUBLICA ARGENTINA - JUZGADOS...  \\\n",
       "1  BOLETIN OFICIAL REPUBLICA ARGENTINA - JUZGADO ...   \n",
       "2  BOLETIN OFICIAL REPUBLICA ARGENTINA - JUZGADOS...   \n",
       "3  BOLETIN OFICIAL REPUBLICA ARGENTINA - N° 82\\n ...   \n",
       "\n",
       "                                                body   \n",
       "0  El Juzgado Nacional de Primera Instancia N° 42...  \\\n",
       "1  El Juzgado Nacional de Primera Instancia en lo...   \n",
       "2  Juzgado Nacional de Primera Instancia en lo Ci...   \n",
       "3  La Señora Juez Subrogante a cargo del Juzgado ...   \n",
       "\n",
       "                                                 ref  \n",
       "0  <a class=\"puntero\" href=\"/seccion/segunda/2023...  \n",
       "1  <a class=\"puntero\" href=\"/seccion/segunda/2023...  \n",
       "2  <a class=\"puntero\" href=\"/seccion/segunda/2023...  \n",
       "3  <a class=\"puntero\" href=\"/seccion/segunda/2023...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfjl = pd.read_json('boletin_resultado.jl', lines=True)\n",
    "dfjl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "644e137e-da2e-4cb9-b836-214dcf640bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quotejl.pickle\n",
      "quotejson.pickle\n"
     ]
    }
   ],
   "source": [
    "#dfjson.to_pickle('quotejson.pickle')\n",
    "dfjl.to_pickle('quotejl.pickle')\n",
    "!ls *pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8d4eff0-7704-4c3f-a94f-a10fb601d87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('quoteresult.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1500922-2a13-4a36-8427-cebd72a6a3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = [\n",
    "        'http://quotes.toscrape.com/page/1/',\n",
    "        'http://quotes.toscrape.com/page/2/',\n",
    "    ]\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'quoteresult.json'                        # Used for pipeline 2\n",
    "    }\n",
    "    \n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.quote'):\n",
    "            yield {\n",
    "                'text': quote.css('span.text::text').extract_first(),\n",
    "                'author': quote.css('span small::text').extract_first(),\n",
    "                'tags': quote.css('div.tags a.tag::text').extract(),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f7a81b-68ee-42f4-b1e4-5e5684f67c58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 12:00:34 [scrapy.utils.log] INFO: Scrapy 2.8.0 started (bot: scrapybot)\n",
      "2023-05-04 12:00:34 [scrapy.utils.log] INFO: Versions: lxml 4.9.2.0, libxml2 2.9.12, cssselect 1.2.0, parsel 1.8.1, w3lib 2.1.1, Twisted 22.10.0, Python 3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:32:50) [MSC v.1929 64 bit (AMD64)], pyOpenSSL 23.1.1 (OpenSSL 3.1.0 14 Mar 2023), cryptography 40.0.1, Platform Windows-10-10.0.19044-SP0\n",
      "2023-05-04 12:00:34 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 30,\n",
      " 'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'}\n",
      "2023-05-04 12:00:34 [py.warnings] WARNING: C:\\Users\\juani\\anaconda3\\envs\\llm\\lib\\site-packages\\scrapy\\utils\\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2023-05-04 12:00:34 [py.warnings] WARNING: C:\\Users\\juani\\anaconda3\\envs\\llm\\lib\\site-packages\\scrapy\\extensions\\feedexport.py:315: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details\n",
      "  exporter = cls(crawler)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Deferred at 0x28493cdc760>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-04 12:00:35 [py.warnings] WARNING: C:\\Users\\juani\\anaconda3\\envs\\llm\\lib\\site-packages\\scrapy\\selector\\unified.py:83: UserWarning: Selector got both text and root, root is being ignored.\n",
      "  super().__init__(text=text, type=st, root=root, **kwargs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
    "})\n",
    "\n",
    "process.crawl(QuotesSpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2434170e-10bf-40d1-822a-93ea90690b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quoteresult.jl\n",
      "quoteresult.json\n"
     ]
    }
   ],
   "source": [
    "!ls quoteresult.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab3df06b-b7cc-4a21-8633-52d7171c1e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\": \"\\u201cA woman is like a tea bag; you never know how strong it is until it's in hot water.\\u201d\", \"author\": \"Eleanor Roosevelt\", \"tags\": [\"misattributed-eleanor-roosevelt\"]}\n",
      "{\"text\": \"\\u201cA day without sunshine is like, you know, night.\\u201d\", \"author\": \"Steve Martin\", \"tags\": [\"humor\", \"obvious\", \"simile\"]}\n"
     ]
    }
   ],
   "source": [
    "!tail -n 2 quoteresult.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4144779a-0e49-436c-b7d4-f946417931d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"text\": \"\\u201cA day without sunshine is like, you know, night.\\u201d\", \"author\": \"Steve Martin\", \"tags\": [\"humor\", \"obvious\", \"simile\"]}\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "!tail -n 2 quoteresult.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37b12a98-253b-4b3c-9025-00099b6f1b82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“This life is what you make it. No matter what...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>[friends, heartbreak, inspirational, life, lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“It takes a great deal of bravery to stand up ...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>[courage, friends]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“If you can't explain it to a six year old, yo...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[simplicity, understand]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“You may not be her first, her last, or her on...</td>\n",
       "      <td>Bob Marley</td>\n",
       "      <td>[love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“I like nonsense, it wakes up the brain cells....</td>\n",
       "      <td>Dr. Seuss</td>\n",
       "      <td>[fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“I may not have gone where I intended to go, b...</td>\n",
       "      <td>Douglas Adams</td>\n",
       "      <td>[life, navigation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>“The opposite of love is not hate, it's indiff...</td>\n",
       "      <td>Elie Wiesel</td>\n",
       "      <td>[activism, apathy, hate, indifference, inspira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>“It is not a lack of love, but a lack of frien...</td>\n",
       "      <td>Friedrich Nietzsche</td>\n",
       "      <td>[friendship, lack-of-friendship, lack-of-love,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>“Good friends, good books, and a sleepy consci...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>[books, contentment, friends, friendship, life]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>“Life is what happens to us while we are makin...</td>\n",
       "      <td>Allen Saunders</td>\n",
       "      <td>[fate, life, misattributed-john-lennon, planni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>“The world as we have created it is a process ...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[change, deep-thoughts, thinking, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>“It is our choices, Harry, that show what we t...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>[abilities, choices]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>“There are only two ways to live your life. On...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[inspirational, life, live, miracle, miracles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>[aliteracy, books, classic, humor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>[be-yourself, inspirational]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>“Try not to become a man of success. Rather be...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[adulthood, success, value]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>“It is better to be hated for what you are tha...</td>\n",
       "      <td>André Gide</td>\n",
       "      <td>[life, love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>“I have not failed. I've just found 10,000 way...</td>\n",
       "      <td>Thomas A. Edison</td>\n",
       "      <td>[edison, failure, inspirational, paraphrased]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>“A woman is like a tea bag; you never know how...</td>\n",
       "      <td>Eleanor Roosevelt</td>\n",
       "      <td>[misattributed-eleanor-roosevelt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“A day without sunshine is like, you know, nig...</td>\n",
       "      <td>Steve Martin</td>\n",
       "      <td>[humor, obvious, simile]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text               author   \n",
       "0   “This life is what you make it. No matter what...       Marilyn Monroe  \\\n",
       "1   “It takes a great deal of bravery to stand up ...         J.K. Rowling   \n",
       "2   “If you can't explain it to a six year old, yo...      Albert Einstein   \n",
       "3   “You may not be her first, her last, or her on...           Bob Marley   \n",
       "4   “I like nonsense, it wakes up the brain cells....            Dr. Seuss   \n",
       "5   “I may not have gone where I intended to go, b...        Douglas Adams   \n",
       "6   “The opposite of love is not hate, it's indiff...          Elie Wiesel   \n",
       "7   “It is not a lack of love, but a lack of frien...  Friedrich Nietzsche   \n",
       "8   “Good friends, good books, and a sleepy consci...           Mark Twain   \n",
       "9   “Life is what happens to us while we are makin...       Allen Saunders   \n",
       "10  “The world as we have created it is a process ...      Albert Einstein   \n",
       "11  “It is our choices, Harry, that show what we t...         J.K. Rowling   \n",
       "12  “There are only two ways to live your life. On...      Albert Einstein   \n",
       "13  “The person, be it gentleman or lady, who has ...          Jane Austen   \n",
       "14  “Imperfection is beauty, madness is genius and...       Marilyn Monroe   \n",
       "15  “Try not to become a man of success. Rather be...      Albert Einstein   \n",
       "16  “It is better to be hated for what you are tha...           André Gide   \n",
       "17  “I have not failed. I've just found 10,000 way...     Thomas A. Edison   \n",
       "18  “A woman is like a tea bag; you never know how...    Eleanor Roosevelt   \n",
       "19  “A day without sunshine is like, you know, nig...         Steve Martin   \n",
       "\n",
       "                                                 tags  \n",
       "0   [friends, heartbreak, inspirational, life, lov...  \n",
       "1                                  [courage, friends]  \n",
       "2                            [simplicity, understand]  \n",
       "3                                              [love]  \n",
       "4                                           [fantasy]  \n",
       "5                                  [life, navigation]  \n",
       "6   [activism, apathy, hate, indifference, inspira...  \n",
       "7   [friendship, lack-of-friendship, lack-of-love,...  \n",
       "8     [books, contentment, friends, friendship, life]  \n",
       "9   [fate, life, misattributed-john-lennon, planni...  \n",
       "10           [change, deep-thoughts, thinking, world]  \n",
       "11                               [abilities, choices]  \n",
       "12     [inspirational, life, live, miracle, miracles]  \n",
       "13                 [aliteracy, books, classic, humor]  \n",
       "14                       [be-yourself, inspirational]  \n",
       "15                        [adulthood, success, value]  \n",
       "16                                       [life, love]  \n",
       "17      [edison, failure, inspirational, paraphrased]  \n",
       "18                  [misattributed-eleanor-roosevelt]  \n",
       "19                           [humor, obvious, simile]  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfjson = pd.read_json('quoteresult.json')\n",
    "dfjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94606635-519d-4683-96c7-2ff14dff1cc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“This life is what you make it. No matter what...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>[friends, heartbreak, inspirational, life, lov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>“It takes a great deal of bravery to stand up ...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>[courage, friends]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>“If you can't explain it to a six year old, yo...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[simplicity, understand]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>“You may not be her first, her last, or her on...</td>\n",
       "      <td>Bob Marley</td>\n",
       "      <td>[love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>“I like nonsense, it wakes up the brain cells....</td>\n",
       "      <td>Dr. Seuss</td>\n",
       "      <td>[fantasy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>“I may not have gone where I intended to go, b...</td>\n",
       "      <td>Douglas Adams</td>\n",
       "      <td>[life, navigation]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>“The opposite of love is not hate, it's indiff...</td>\n",
       "      <td>Elie Wiesel</td>\n",
       "      <td>[activism, apathy, hate, indifference, inspira...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>“It is not a lack of love, but a lack of frien...</td>\n",
       "      <td>Friedrich Nietzsche</td>\n",
       "      <td>[friendship, lack-of-friendship, lack-of-love,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>“Good friends, good books, and a sleepy consci...</td>\n",
       "      <td>Mark Twain</td>\n",
       "      <td>[books, contentment, friends, friendship, life]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>“Life is what happens to us while we are makin...</td>\n",
       "      <td>Allen Saunders</td>\n",
       "      <td>[fate, life, misattributed-john-lennon, planni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>“The world as we have created it is a process ...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[change, deep-thoughts, thinking, world]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>“It is our choices, Harry, that show what we t...</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>[abilities, choices]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>“There are only two ways to live your life. On...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[inspirational, life, live, miracle, miracles]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>“The person, be it gentleman or lady, who has ...</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>[aliteracy, books, classic, humor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>“Imperfection is beauty, madness is genius and...</td>\n",
       "      <td>Marilyn Monroe</td>\n",
       "      <td>[be-yourself, inspirational]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>“Try not to become a man of success. Rather be...</td>\n",
       "      <td>Albert Einstein</td>\n",
       "      <td>[adulthood, success, value]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>“It is better to be hated for what you are tha...</td>\n",
       "      <td>André Gide</td>\n",
       "      <td>[life, love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>“I have not failed. I've just found 10,000 way...</td>\n",
       "      <td>Thomas A. Edison</td>\n",
       "      <td>[edison, failure, inspirational, paraphrased]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>“A woman is like a tea bag; you never know how...</td>\n",
       "      <td>Eleanor Roosevelt</td>\n",
       "      <td>[misattributed-eleanor-roosevelt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>“A day without sunshine is like, you know, nig...</td>\n",
       "      <td>Steve Martin</td>\n",
       "      <td>[humor, obvious, simile]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text               author   \n",
       "0   “This life is what you make it. No matter what...       Marilyn Monroe  \\\n",
       "1   “It takes a great deal of bravery to stand up ...         J.K. Rowling   \n",
       "2   “If you can't explain it to a six year old, yo...      Albert Einstein   \n",
       "3   “You may not be her first, her last, or her on...           Bob Marley   \n",
       "4   “I like nonsense, it wakes up the brain cells....            Dr. Seuss   \n",
       "5   “I may not have gone where I intended to go, b...        Douglas Adams   \n",
       "6   “The opposite of love is not hate, it's indiff...          Elie Wiesel   \n",
       "7   “It is not a lack of love, but a lack of frien...  Friedrich Nietzsche   \n",
       "8   “Good friends, good books, and a sleepy consci...           Mark Twain   \n",
       "9   “Life is what happens to us while we are makin...       Allen Saunders   \n",
       "10  “The world as we have created it is a process ...      Albert Einstein   \n",
       "11  “It is our choices, Harry, that show what we t...         J.K. Rowling   \n",
       "12  “There are only two ways to live your life. On...      Albert Einstein   \n",
       "13  “The person, be it gentleman or lady, who has ...          Jane Austen   \n",
       "14  “Imperfection is beauty, madness is genius and...       Marilyn Monroe   \n",
       "15  “Try not to become a man of success. Rather be...      Albert Einstein   \n",
       "16  “It is better to be hated for what you are tha...           André Gide   \n",
       "17  “I have not failed. I've just found 10,000 way...     Thomas A. Edison   \n",
       "18  “A woman is like a tea bag; you never know how...    Eleanor Roosevelt   \n",
       "19  “A day without sunshine is like, you know, nig...         Steve Martin   \n",
       "\n",
       "                                                 tags  \n",
       "0   [friends, heartbreak, inspirational, life, lov...  \n",
       "1                                  [courage, friends]  \n",
       "2                            [simplicity, understand]  \n",
       "3                                              [love]  \n",
       "4                                           [fantasy]  \n",
       "5                                  [life, navigation]  \n",
       "6   [activism, apathy, hate, indifference, inspira...  \n",
       "7   [friendship, lack-of-friendship, lack-of-love,...  \n",
       "8     [books, contentment, friends, friendship, life]  \n",
       "9   [fate, life, misattributed-john-lennon, planni...  \n",
       "10           [change, deep-thoughts, thinking, world]  \n",
       "11                               [abilities, choices]  \n",
       "12     [inspirational, life, live, miracle, miracles]  \n",
       "13                 [aliteracy, books, classic, humor]  \n",
       "14                       [be-yourself, inspirational]  \n",
       "15                        [adulthood, success, value]  \n",
       "16                                       [life, love]  \n",
       "17      [edison, failure, inspirational, paraphrased]  \n",
       "18                  [misattributed-eleanor-roosevelt]  \n",
       "19                           [humor, obvious, simile]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfjl = pd.read_json('quoteresult.jl', lines=True)\n",
    "dfjl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1003ba04-f99f-465f-9f55-bcd82e39d11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quotejl.pickle\n",
      "quotejson.pickle\n"
     ]
    }
   ],
   "source": [
    "dfjson.to_pickle('quotejson.pickle')\n",
    "dfjl.to_pickle('quotejl.pickle')\n",
    "!ls *pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4d8697-c0d9-4bcc-8036-5f89586276bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e549154-a53f-4aa5-8f94-7754c9b00373",
   "metadata": {},
   "source": [
    "# Caso Intento Productivo I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07431e22-2a3b-4647-a1e2-f2a595f2a301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\juani\\\\Documents\\\\3_My_Jupiter_Notebooks\\\\5_Galicia\\\\2_LLMs\\\\venv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "from crochet import setup, wait_for\n",
    "\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\juani\\\\Documents\\\\3_My_Jupiter_Notebooks\\\\5_Galicia\\\\2_LLMs\\\\venv')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cee9ef2d-4e03-47de-acbe-a8caf952fdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('boletin_resultado.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0e50d03f-377b-4d5b-8eb2-c8b587267e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A{(7-len(str(i)))*\"0\"}{i}/20230503' for i in np.arange(1,1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebfa7249-5f84-4676-9b04-67d0005a4e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ls =  [str(i) for i in np.arange(1,100)]\n",
    "full_ls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A0000001/20230503'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76c058a3-5059-4a9a-aa8f-859bfc58d43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup()\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    start_urls = urls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A{(7-len(str(i)))*\"0\"}{i}/20230503' for i in np.arange(1,1000)]\n",
    "    \n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        #'CONCURRENT_REQUESTS_PER_IP':0,\n",
    "        'COOKIES_ENABLED':False,\n",
    "        'DOWNLOAD_DELAY' : 0.25,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'boletin_resultado.json'                        # Used for pipeline 2\n",
    "    }\n",
    "    num=0\n",
    "    def parse(self, response):\n",
    "        num += 1\n",
    "        text = response.xpath('//title/text()').get()\n",
    "        body = response.css('div.avisoContenido article div#detalleAviso div#tituloDetalleAviso + div#cuerpoDetalleAviso p::text').get()\n",
    "        ref = response.xpath('/html/body/div[4]/div/div[2]/div/div[2]/div/div[2]/div[1]/ol/li[2]/a').get() # ::text\n",
    "        # print(text,body,ref)\n",
    "        print(num,text)\n",
    "        yield {\n",
    "                'text': text,\n",
    "                'body': body,\n",
    "                'ref': ref\n",
    "            } \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17359074-440c-4a37-bb3a-daab46d531ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m     d \u001b[38;5;241m=\u001b[39m crawler\u001b[38;5;241m.\u001b[39mcrawl(QuotesSpider)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m d\n\u001b[1;32m----> 7\u001b[0m \u001b[43mrun_spider\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m   \n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\crochet\\_eventloop.py:461\u001b[0m, in \u001b[0;36mEventLoop.wait_for.<locals>.decorator.<locals>.wrapper\u001b[1;34m(function, _, args, kwargs)\u001b[0m\n\u001b[0;32m    459\u001b[0m eventual_result \u001b[38;5;241m=\u001b[39m run()\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meventual_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m:\n\u001b[0;32m    463\u001b[0m     eventual_result\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\crochet\\_eventloop.py:196\u001b[0m, in \u001b[0;36mEventualResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threadable\u001b[38;5;241m.\u001b[39misInIOThread():\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEventualResult.wait() must not be run in the reactor thread.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 196\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Failure):\n\u001b[0;32m    198\u001b[0m     result\u001b[38;5;241m.\u001b[39mraiseException()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\crochet\\_eventloop.py:175\u001b[0m, in \u001b[0;36mEventualResult._result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# In Python 2.6 we can't rely on the return result of wait(), so we\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# have to check manually:\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_set\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_retrieved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[1;31mTimeoutError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "@wait_for(10)\n",
    "def run_spider():\n",
    "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(QuotesSpider)\n",
    "    return d\n",
    "run_spider()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ea5175c-4da3-4cfa-9ac1-f48051b9ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfjson = pd.read_json('boletin_resultado.json')\n",
    "# dfjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d2b7fd9b-f03c-4d38-a666-c6f53a9ad22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<a class=\"puntero\" href=\"/seccion/segunda/20230503?rubro=3100\">CITACIONES Y NOTIFICACIONES. CONCURSOS Y QUIEBRAS. OTROS</a>'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfjl.ref[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d356485a-54ca-42e6-ac9e-5e79eccd09b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfjl = pd.read_json('boletin_resultado.jl', lines=True)\n",
    "dfjl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "43aca427-bc52-4887-abe2-b8b96d6ee50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quotejl.pickle\n",
      "quotejson.pickle\n",
      "BOLETIN OFICIAL REPUBLICA ARGENTINA None None\n",
      "BOLETIN OFICIAL REPUBLICA ARGENTINA None None\n",
      "BOLETIN OFICIAL REPUBLICA ARGENTINA None None\n",
      "BOLETIN OFICIAL REPUBLICA ARGENTINA None None\n"
     ]
    }
   ],
   "source": [
    "#dfjson.to_pickle('quotejson.pickle')\n",
    "dfjl.to_pickle('quotejl.pickle')\n",
    "!ls *pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18fbe1-2821-4988-9e4b-47615e40e961",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd7ee47b-3535-4528-a0c2-a9e235515f97",
   "metadata": {},
   "source": [
    "# Caso Intento Productivo II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50834435-7ffa-41d5-9c8c-e2d357c4e14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\juani\\\\Documents\\\\3_My_Jupiter_Notebooks\\\\5_Galicia\\\\2_LLMs\\\\venv'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import logging\n",
    "\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "from crochet import setup, wait_for\n",
    "\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\juani\\\\Documents\\\\3_My_Jupiter_Notebooks\\\\5_Galicia\\\\2_LLMs\\\\venv')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9a92f723-b7db-4638-9c3f-8df1fce7415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A{(7-len(str(i)))*\"0\"}{i}/20230503' for i in np.arange(1,1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1dd0cb-655a-4b93-a2e0-dfd45dda492c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (1711122952.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[17], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    full_ls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A0000001/20230503'\u001b[0m\n\u001b[1;37m                                                                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "num_ls =  [str(i) for i in np.arange(1,100)]\n",
    "full_ls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A0000001/20230503'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "707e69da-0d84-48f4-a8ec-fb19e834a9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy import Spider\n",
    "from scrapy import signals\n",
    "from scrapy.downloadermiddlewares.useragent import UserAgentMiddleware\n",
    "from scrapy.downloadermiddlewares.httpproxy import HttpProxyMiddleware\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0f10685-7838-46ae-92a1-3a6f7f4fb5f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A0000099/20230503'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A{(7-len(str(i)))*\"0\"}{i}/20230503' for i in np.arange(1,101)]\n",
    "urls[98]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c2c2486-b9d1-44a5-ba51-58315f35d0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A0000011/20230503'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A{(7-len(str(i)))*\"0\"}{i}/20230503' for i in np.arange(1,10000)]\n",
    "urls[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "463e3755-53b5-415a-82b5-2bd2092c4f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.downloadermiddlewares.retry import RetryMiddleware\n",
    "from twisted.internet.error import TCPTimedOutError, TimeoutError\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "243e5c28-bcdf-4053-9091-ea6947e6307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infinite_sequence():\n",
    "    num = 1\n",
    "    while True:\n",
    "        yield num\n",
    "        num += 1\n",
    "gen = infinite_sequence()\n",
    "\n",
    "\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('boletin_resultado.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item\n",
    "    \n",
    "setup()\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        #'CONCURRENT_REQUESTS_PER_IP':0,\n",
    "        'COOKIES_ENABLED':False, # False True\n",
    "        'DOWNLOAD_DELAY' : 0.1,\n",
    "        \"ROBOTSTXT_OBEY\":False,\n",
    "        # Example Scrapy settings\n",
    "        #'DOWNLOAD_TIMEOUT' : 30,\n",
    "        'REACTOR_THREADPOOL_MAXSIZE' : 20,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'boletin_resultado.json'                        # Used for pipeline 2\n",
    "    }\n",
    "    user_agent_list = [\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.5 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.53 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Windows; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.114 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Windows; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.114 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.53 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Windows; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.114 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.53 Safari/537.36\"\n",
    "  ]\n",
    "    def start_requests(self):\n",
    "        urls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A{(7-len(str(i)))*\"0\"}{i}/20230503' for i in np.arange(1,200)]\n",
    "        # random.shuffle(urls)\n",
    "        for i, url in enumerate(urls):\n",
    "            yield scrapy.Request(url, callback=self.parse,headers={\"User-Agent\": self.user_agent_list[random.randint(0, len(self.user_agent_list)-1)]})\n",
    "    \n",
    "    def process_exception(self, request, exception, spider):   \n",
    "        if isinstance(exception, TimeoutError) or isinstance(exception, TCPTimedOutError): \n",
    "            return self._retry(request, exception, spider)\n",
    "    def errback_httpbin(self, failure):\n",
    "        # log all errback failures,\n",
    "        # in case you want to do something special for some errors,\n",
    "        # you may need the failure's type\n",
    "        self.logger.error(repr(failure))\n",
    "\n",
    "        #if isinstance(failure.value, HttpError):\n",
    "        if failure.check(HttpError):\n",
    "            # you can get the response\n",
    "            response = failure.value.response\n",
    "            self.logger.error('HttpError on %s', response.url)\n",
    "\n",
    "        #elif isinstance(failure.value, DNSLookupError):\n",
    "        elif failure.check(DNSLookupError):\n",
    "            # this is the original request\n",
    "            request = failure.request\n",
    "            self.logger.error('DNSLookupError on %s', request.url)\n",
    "\n",
    "        #elif isinstance(failure.value, TimeoutError):\n",
    "        elif failure.check(TimeoutError):\n",
    "            request = failure.request\n",
    "            self.logger.error('TimeoutError on %s', request.url)\n",
    "            \n",
    "    def parse(self, response):\n",
    "        title = response.xpath('//title/text()').get()\n",
    "        subtitle = response.xpath('/html/body/div[4]/div/div[2]/div/div[2]/div/div[2]/div[1]/ol/li[2]/a/text()').get() # ::text\n",
    "        body = response.css('div.avisoContenido article div#detalleAviso div#tituloDetalleAviso + div#cuerpoDetalleAviso p::text').get()\n",
    "        \n",
    "        print(next(gen),subtitle,end=\"\\r\")\n",
    "\n",
    "\n",
    "        yield { \n",
    "                'title': title,\n",
    "                'subtitle': subtitle,\n",
    "                'body': body\n",
    "            } \n",
    "\n",
    "@wait_for(10)\n",
    "def run_spider():\n",
    "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(QuotesSpider)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "979a1aa8-ce7c-49b8-9e8c-f6a4175f63ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "354 CITACIONES Y NOTIFICACIONES. CONCURSOS Y QUIEBRAS. OTROS\r"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mrun_spider\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\crochet\\_eventloop.py:461\u001b[0m, in \u001b[0;36mEventLoop.wait_for.<locals>.decorator.<locals>.wrapper\u001b[1;34m(function, _, args, kwargs)\u001b[0m\n\u001b[0;32m    459\u001b[0m eventual_result \u001b[38;5;241m=\u001b[39m run()\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meventual_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m:\n\u001b[0;32m    463\u001b[0m     eventual_result\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\crochet\\_eventloop.py:196\u001b[0m, in \u001b[0;36mEventualResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threadable\u001b[38;5;241m.\u001b[39misInIOThread():\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEventualResult.wait() must not be run in the reactor thread.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 196\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Failure):\n\u001b[0;32m    198\u001b[0m     result\u001b[38;5;241m.\u001b[39mraiseException()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\crochet\\_eventloop.py:175\u001b[0m, in \u001b[0;36mEventualResult._result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# In Python 2.6 we can't rely on the return result of wait(), so we\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# have to check manually:\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_set\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_retrieved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[1;31mTimeoutError\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374 NoneCIONES Y NOTIFICACIONES. CONCURSOS Y QUIEBRAS. OTROS\r"
     ]
    }
   ],
   "source": [
    "run_spider() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6893a05f-03c5-4041-808d-2879366f02a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149 CITACIONES Y NOTIFICACIONES. CONCURSOS Y QUIEBRAS. OTROS\r"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mrun_spider\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\crochet\\_eventloop.py:461\u001b[0m, in \u001b[0;36mEventLoop.wait_for.<locals>.decorator.<locals>.wrapper\u001b[1;34m(function, _, args, kwargs)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meventual_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\crochet\\_eventloop.py:196\u001b[0m, in \u001b[0;36mEventualResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEventualResult.wait() must not be run in the reactor thread.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 196\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Failure):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\crochet\\_eventloop.py:175\u001b[0m, in \u001b[0;36mEventualResult._result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_set\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_retrieved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m     run_spider()  \n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mrun_spider\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\crochet\\_eventloop.py:461\u001b[0m, in \u001b[0;36mEventLoop.wait_for.<locals>.decorator.<locals>.wrapper\u001b[1;34m(function, _, args, kwargs)\u001b[0m\n\u001b[0;32m    459\u001b[0m eventual_result \u001b[38;5;241m=\u001b[39m run()\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meventual_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m:\n\u001b[0;32m    463\u001b[0m     eventual_result\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\crochet\\_eventloop.py:196\u001b[0m, in \u001b[0;36mEventualResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threadable\u001b[38;5;241m.\u001b[39misInIOThread():\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEventualResult.wait() must not be run in the reactor thread.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 196\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Failure):\n\u001b[0;32m    198\u001b[0m     result\u001b[38;5;241m.\u001b[39mraiseException()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\crochet\\_eventloop.py:175\u001b[0m, in \u001b[0;36mEventualResult._result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# In Python 2.6 we can't rely on the return result of wait(), so we\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# have to check manually:\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_set\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_retrieved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[1;31mTimeoutError\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170 NoneCIONES Y NOTIFICACIONES. CONCURSOS Y QUIEBRAS. OTROS\r"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    run_spider()  \n",
    "except:\n",
    "    run_spider() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8c357381-906a-4d8d-a3c7-6c1dd7dbc331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfjson = pd.read_json('boletin_resultado.json')\n",
    "# dfjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bde2dd51-3460-48aa-bd0e-d41ba02392fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfjl['sub'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10d361e7-4237-4bb7-b301-7258b6b03cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfjl = pd.read_json('boletin_resultado.jl', lines=True)\n",
    "len(dfjl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "28607bc3-00bd-4528-ac92-146d533b309a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quotejl.pickle\n",
      "quotejson.pickle\n",
      "BOLETIN OFICIAL REPUBLICA ARGENTINA None None\n",
      "BOLETIN OFICIAL REPUBLICA ARGENTINA None None\n",
      "BOLETIN OFICIAL REPUBLICA ARGENTINA None None\n",
      "BOLETIN OFICIAL REPUBLICA ARGENTINA None None\n"
     ]
    }
   ],
   "source": [
    "#dfjson.to_pickle('quotejson.pickle')\n",
    "dfjl.to_pickle('quotejl.pickle')\n",
    "!ls *pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a39c0a-ab7d-412f-85c9-01fe5705cecf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Caso Intento Productivo III header rotante"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50af447f-f8f9-4189-8e1f-c0df5489d912",
   "metadata": {},
   "source": [
    "https://scrapeops.io/app/settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "554c24c5-d4bd-4dd0-bfdc-c4b2b15238b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## middlewares.py\n",
    "\n",
    "from urllib.parse import urlencode\n",
    "from random import randint\n",
    "import requests\n",
    "\n",
    "class ScrapeOpsFakeBrowserHeaderAgentMiddleware:\n",
    "\n",
    "    @classmethod\n",
    "    def from_crawler(cls, crawler):\n",
    "        return cls(crawler.settings)\n",
    "\n",
    "    def __init__(self, settings):\n",
    "        self.scrapeops_api_key = settings.get('SCRAPEOPS_API_KEY')\n",
    "        self.scrapeops_endpoint = settings.get('SCRAPEOPS_FAKE_BROWSER_HEADER_ENDPOINT', 'http://headers.scrapeops.io/v1/browser-headers?') \n",
    "        self.scrapeops_fake_browser_headers_active = settings.get('SCRAPEOPS_FAKE_BROWSER_HEADER_ENABLED', False)\n",
    "        self.scrapeops_num_results = settings.get('SCRAPEOPS_NUM_RESULTS')\n",
    "        self.headers_list = []\n",
    "        self._get_headers_list()\n",
    "        self._scrapeops_fake_browser_headers_enabled()\n",
    "\n",
    "    def _get_headers_list(self):\n",
    "        payload = {'api_key': self.scrapeops_api_key}\n",
    "        if self.scrapeops_num_results is not None:\n",
    "            payload['num_results'] = self.scrapeops_num_results\n",
    "        response = requests.get(self.scrapeops_endpoint, params=urlencode(payload))\n",
    "        json_response = response.json()\n",
    "        self.headers_list = json_response.get('result', [])\n",
    "\n",
    "    def _get_random_browser_header(self):\n",
    "        random_index = randint(0, len(self.headers_list) - 1)\n",
    "        return self.headers_list[random_index]\n",
    "\n",
    "    def _scrapeops_fake_browser_headers_enabled(self):\n",
    "        if self.scrapeops_api_key is None or self.scrapeops_api_key == '' or self.scrapeops_fake_browser_headers_active == False:\n",
    "            self.scrapeops_fake_browser_headers_active = False\n",
    "        else:\n",
    "            self.scrapeops_fake_browser_headers_active = True\n",
    "    \n",
    "    def process_request(self, request, spider):        \n",
    "        random_browser_header = self._get_random_browser_header()\n",
    "        request.headers = random_browser_header\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cebe8b23-d39d-4dd5-b56d-fe69e53e8d2e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bookscraper.middlewares'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 83\u001b[0m\n\u001b[0;32m     81\u001b[0m     d \u001b[38;5;241m=\u001b[39m crawler\u001b[38;5;241m.\u001b[39mcrawl(QuotesSpider)\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m d\n\u001b[1;32m---> 83\u001b[0m \u001b[43mrun_spider\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m   \n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\crochet\\_eventloop.py:461\u001b[0m, in \u001b[0;36mEventLoop.wait_for.<locals>.decorator.<locals>.wrapper\u001b[1;34m(function, _, args, kwargs)\u001b[0m\n\u001b[0;32m    459\u001b[0m eventual_result \u001b[38;5;241m=\u001b[39m run()\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meventual_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m:\n\u001b[0;32m    463\u001b[0m     eventual_result\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\crochet\\_eventloop.py:198\u001b[0m, in \u001b[0;36mEventualResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    196\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result(timeout)\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Failure):\n\u001b[1;32m--> 198\u001b[0m     \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraiseException\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\twisted\\python\\failure.py:504\u001b[0m, in \u001b[0;36mFailure.raiseException\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraiseException\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m    500\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;124;03m    raise the original exception, preserving traceback\u001b[39;00m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;124;03m    information if available.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bookscraper.middlewares'"
     ]
    }
   ],
   "source": [
    "def infinite_sequence():\n",
    "    num = 1\n",
    "    while True:\n",
    "        yield num\n",
    "        num += 1\n",
    "gen = infinite_sequence()\n",
    "\n",
    "\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('boletin_resultado.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item\n",
    "    \n",
    "setup()\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        #'CONCURRENT_REQUESTS_PER_IP':0,\n",
    "        'COOKIES_ENABLED':True,\n",
    "        #'DOWNLOAD_DELAY' : 5,\n",
    "        # Example Scrapy settings\n",
    "        'DOWNLOAD_TIMEOUT' : 180,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, \n",
    "        'FEED_FORMAT':'json',                                 \n",
    "        'FEED_URI': 'boletin_resultado.json',                  \n",
    "        'SCRAPEOPS_API_KEY' : '889b76ad-0bd8-4922-9f7b-596e077b305c',\n",
    "        'SCRAPEOPS_FAKE_BROWSER_HEADER_ENABLED' : True,\n",
    "        'DOWNLOADER_MIDDLEWARES' : {\n",
    "        'bookscraper.middlewares.ScrapeOpsFakeBrowserHeaderAgentMiddleware': 400,\n",
    "}\n",
    "    }\n",
    "    user_agent_list = [\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.5 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.53 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Windows; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.114 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/603.3.8 (KHTML, like Gecko) Version/10.1.2 Safari/603.3.8\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Windows; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.114 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.53 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Windows; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.114 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.5060.53 Safari/537.36\"\n",
    "  ]\n",
    "    def start_requests(self):\n",
    "        urls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A{(7-len(str(i)))*\"0\"}{i}/20230503' for i in np.arange(1,200)]\n",
    "        for i, url in enumerate(urls):\n",
    "            yield scrapy.Request(url, callback=self.parse,headers={\"User-Agent\": self.user_agent_list[random.randint(0, len(self.user_agent_list)-1)]})\n",
    "    \n",
    "    def process_exception(self, request, exception, spider):   \n",
    "        if isinstance(exception, TimeoutError) or isinstance(exception, TCPTimedOutError): \n",
    "            # time.sleep(10)\n",
    "            return self._retry(request, exception, spider)\n",
    "    \n",
    "    def parse(self, response):\n",
    "        title = response.xpath('//title/text()').get()\n",
    "        subtitle = response.xpath('/html/body/div[4]/div/div[2]/div/div[2]/div/div[2]/div[1]/ol/li[2]/a/text()').get() # ::text\n",
    "        body = response.css('div.avisoContenido article div#detalleAviso div#tituloDetalleAviso + div#cuerpoDetalleAviso p::text').get()\n",
    "        \n",
    "        print(next(gen),subtitle,end=\"\\r\")\n",
    "\n",
    "\n",
    "        yield {\n",
    "                'title': title,\n",
    "                'subtitle': subtitle,\n",
    "                'body': body\n",
    "            } \n",
    "\n",
    "@wait_for(10)\n",
    "def run_spider():\n",
    "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(QuotesSpider)\n",
    "    return d\n",
    "run_spider()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7860ffcd-5289-41b9-a755-f3a5897fe2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.28.2\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-645585fe-6fbb535e5ab75c991ccf6a58\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "r = requests.get('http://httpbin.org/headers')\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0563db40-4ae9-4735-9efc-09b05dc5cd1e",
   "metadata": {},
   "source": [
    "# caso gasolero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "30c3aedb-6cb7-4c62-822f-100e5a15c7d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecf353f1-2dfa-40f8-9e60-1eb92429b8f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_headers_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m item\n\u001b[0;32m     22\u001b[0m setup()\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mQuotesSpider\u001b[39;00m(scrapy\u001b[38;5;241m.\u001b[39mSpider):\n\u001b[0;32m     24\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquotes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     25\u001b[0m     header_list \u001b[38;5;241m=\u001b[39m get_headers_list()\n",
      "Cell \u001b[1;32mIn[8], line 25\u001b[0m, in \u001b[0;36mQuotesSpider\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mQuotesSpider\u001b[39;00m(scrapy\u001b[38;5;241m.\u001b[39mSpider):\n\u001b[0;32m     24\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquotes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 25\u001b[0m     header_list \u001b[38;5;241m=\u001b[39m \u001b[43mget_headers_list\u001b[49m()\n\u001b[0;32m     26\u001b[0m     custom_settings \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOG_LEVEL\u001b[39m\u001b[38;5;124m'\u001b[39m: logging\u001b[38;5;241m.\u001b[39mWARNING,\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCONCURRENT_REQUESTS_PER_IP\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFEED_URI\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboletin_resultado.json\u001b[39m\u001b[38;5;124m'\u001b[39m                        \u001b[38;5;66;03m# Used for pipeline 2\u001b[39;00m\n\u001b[0;32m     38\u001b[0m     }\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_headers_list\u001b[39m():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_headers_list' is not defined"
     ]
    }
   ],
   "source": [
    "def infinite_sequence():\n",
    "    num = 1\n",
    "    while True:\n",
    "        yield num\n",
    "        num += 1\n",
    "gen = infinite_sequence()\n",
    "\n",
    "\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('boletin_resultado.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item\n",
    "    \n",
    "setup()\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    header_list = get_headers_list()\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'CONCURRENT_REQUESTS_PER_IP':16,\n",
    "        'COOKIES_ENABLED':True,\n",
    "        #'DOWNLOAD_DELAY' : 0.25,\n",
    "        # Example Scrapy settings\n",
    "        'DOWNLOAD_TIMEOUT' : 180,\n",
    "        'ROBOTSTXT_OBEY' : False,\n",
    "        'HTTPCACHE_ENABLED' : True,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'boletin_resultado.json'                        # Used for pipeline 2\n",
    "    }\n",
    "    def get_headers_list():\n",
    "      response = requests.get('http://headers.scrapeops.io/v1/browser-headers?api_key=' + SCRAPEOPS_API_KEY)\n",
    "      json_response = response.json()\n",
    "      return json_response.get('result', [])\n",
    "    \n",
    "     \n",
    "    \n",
    "    def start_requests(self):\n",
    "        urls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A{(7-len(str(i)))*\"0\"}{i}/20230503' for i in np.arange(1,1000)]\n",
    "        for i, url in enumerate(urls):\n",
    "            yield scrapy.Request(url, callback=self.parse,headers= self.header_list[random.randint(0, len(self.header_list)-1)] )\n",
    "    \n",
    "    def process_exception(self, request, exception, spider):   \n",
    "        if isinstance(exception, TimeoutError) or isinstance(exception, TCPTimedOutError): \n",
    "            # time.sleep(10)\n",
    "            return self._retry(request, exception, spider)\n",
    "    \n",
    "    def parse(self, response):\n",
    "        title = response.xpath('//title/text()').get()\n",
    "        subtitle = response.xpath('/html/body/div[4]/div/div[2]/div/div[2]/div/div[2]/div[1]/ol/li[2]/a/text()').get() # ::text\n",
    "        body = response.css('div.avisoContenido article div#detalleAviso div#tituloDetalleAviso + div#cuerpoDetalleAviso p::text').get()\n",
    "        \n",
    "        print(next(gen),subtitle,end=\"\\r\")\n",
    "\n",
    "\n",
    "        yield {\n",
    "                'title': title,\n",
    "                'subtitle': subtitle,\n",
    "                'body': body\n",
    "            } \n",
    "\n",
    "@wait_for(10)\n",
    "def run_spider():\n",
    "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(QuotesSpider)\n",
    "    return d\n",
    "run_spider()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb9ddb7-bb82-4996-aa34-21a1bd21dbc9",
   "metadata": {},
   "source": [
    "# ROTATING PROXIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c30e812e-a1db-49b0-a504-abba13aa58d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapy-rotating-proxies\n",
      "  Downloading scrapy_rotating_proxies-0.6.2-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: six in c:\\users\\juani\\anaconda3\\envs\\llm\\lib\\site-packages (from scrapy-rotating-proxies) (1.16.0)\n",
      "Collecting typing\n",
      "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
      "     ---------------------------------------- 0.0/78.6 kB ? eta -:--:--\n",
      "     ----- ---------------------------------- 10.2/78.6 kB ? eta -:--:--\n",
      "     ----------------------------- -------- 61.4/78.6 kB 812.7 kB/s eta 0:00:01\n",
      "     -------------------------------------- 78.6/78.6 kB 876.3 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: attrs>16.0.0 in c:\\users\\juani\\anaconda3\\envs\\llm\\lib\\site-packages (from scrapy-rotating-proxies) (22.2.0)\n",
      "Building wheels for collected packages: typing\n",
      "  Building wheel for typing (setup.py): started\n",
      "  Building wheel for typing (setup.py): finished with status 'done'\n",
      "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26328 sha256=1f11acbd801d4b084ce1b8484caa214e6356c0ea21bbad0ba2476947f8121d5d\n",
      "  Stored in directory: c:\\users\\juani\\appdata\\local\\pip\\cache\\wheels\\7c\\d0\\9e\\1f26ebb66d9e1732e4098bc5a6c2d91f6c9a529838f0284890\n",
      "Successfully built typing\n",
      "Installing collected packages: typing, scrapy-rotating-proxies\n",
      "Successfully installed scrapy-rotating-proxies-0.6.2 typing-3.7.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scrapy-rotating-proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d4f62c-acf7-4ff6-b46e-87f42365d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy_ls = '103.30.182.116:80,109.236.44.178:8080,111.225.152.56:8089,111.225.152.70:8089,111225153100:8089,114.106.173.32:8089,116197132168:8989,117.54.114.101:80,119.76.142.206:8080,123.182.58.135:8089,159.203.61.169:8080,164.90.183.34:80,183.165.250.4:8089,198.44.188.224:45787,221.225.81.91:3128,34.102.16.169:8585,34.106.65.11:8585,35.228.251.0:8080,45175237194:999,45.92.108.112:80,58234116197:8193,62.89.9.10:8080,94130237161:8080,102.0.0.118:32650,105.16.115.202:80,113.53.53.7:8080,134.209.29.120:3128,138.68.60.8:8080'.split(',')\n",
    "len(proxy_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2226a6cd-12b9-4a5e-ab02-8aa2f2935135",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'logging' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 23\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m item\n\u001b[0;32m     22\u001b[0m setup()\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mQuotesSpider\u001b[39;00m(scrapy\u001b[38;5;241m.\u001b[39mSpider):\n\u001b[0;32m     24\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquotes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m#header_list = get_headers_list()\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 27\u001b[0m, in \u001b[0;36mQuotesSpider\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquotes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m#header_list = get_headers_list()\u001b[39;00m\n\u001b[0;32m     26\u001b[0m custom_settings \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOG_LEVEL\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mlogging\u001b[49m\u001b[38;5;241m.\u001b[39mWARNING,\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCONCURRENT_REQUESTS_PER_IP\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOOKIES_ENABLED\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDOWNLOAD_DELAY\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m0.25\u001b[39m,\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Example Scrapy settings\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDOWNLOAD_TIMEOUT\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;241m180\u001b[39m,\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mROBOTSTXT_OBEY\u001b[39m\u001b[38;5;124m'\u001b[39m : \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mITEM_PIPELINES\u001b[39m\u001b[38;5;124m'\u001b[39m: {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__.JsonWriterPipeline\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m}, \u001b[38;5;66;03m# Used for pipeline 1\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFEED_FORMAT\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m'\u001b[39m,                                 \u001b[38;5;66;03m# Used for pipeline 2\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFEED_URI\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mboletin_resultado.json\u001b[39m\u001b[38;5;124m'\u001b[39m                        \u001b[38;5;66;03m# Used for pipeline 2\u001b[39;00m\n\u001b[0;32m     37\u001b[0m }\n\u001b[0;32m     39\u001b[0m proxy_ls \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m103.30.182.116:80,109.236.44.178:8080,111.225.152.56:8089,111.225.152.70:8089,111225153100:8089,114.106.173.32:8089,116197132168:8989,117.54.114.101:80,119.76.142.206:8080,123.182.58.135:8089,159.203.61.169:8080,164.90.183.34:80,183.165.250.4:8089,198.44.188.224:45787,221.225.81.91:3128,34.102.16.169:8585,34.106.65.11:8585,35.228.251.0:8080,45175237194:999,45.92.108.112:80,58234116197:8193,62.89.9.10:8080,94130237161:8080,102.0.0.118:32650,105.16.115.202:80,113.53.53.7:8080,134.209.29.120:3128,138.68.60.8:8080\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_requests\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'logging' is not defined"
     ]
    }
   ],
   "source": [
    "def infinite_sequence():\n",
    "    num = 1\n",
    "    while True:\n",
    "        yield num\n",
    "        num += 1\n",
    "gen = infinite_sequence()\n",
    "\n",
    "\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('boletin_resultado.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item\n",
    "    \n",
    "setup()\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    #header_list = get_headers_list()\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'CONCURRENT_REQUESTS_PER_IP':20,\n",
    "        'COOKIES_ENABLED':True,\n",
    "        'DOWNLOAD_DELAY' : 0.25,\n",
    "        # Example Scrapy settings\n",
    "        'DOWNLOAD_TIMEOUT' : 180,\n",
    "        'ROBOTSTXT_OBEY' : False,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'boletin_resultado.json'                        # Used for pipeline 2\n",
    "    }\n",
    "    \n",
    "    proxy_ls = '103.30.182.116:80,109.236.44.178:8080,111.225.152.56:8089,111.225.152.70:8089,111225153100:8089,114.106.173.32:8089,116197132168:8989,117.54.114.101:80,119.76.142.206:8080,123.182.58.135:8089,159.203.61.169:8080,164.90.183.34:80,183.165.250.4:8089,198.44.188.224:45787,221.225.81.91:3128,34.102.16.169:8585,34.106.65.11:8585,35.228.251.0:8080,45175237194:999,45.92.108.112:80,58234116197:8193,62.89.9.10:8080,94130237161:8080,102.0.0.118:32650,105.16.115.202:80,113.53.53.7:8080,134.209.29.120:3128,138.68.60.8:8080'.split(',')\n",
    "\n",
    "    \n",
    "    def start_requests(self):\n",
    "        urls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A{(7-len(str(i)))*\"0\"}{i}/20230503' for i in np.arange(1,1000)]\n",
    "        for i, url in enumerate(urls):\n",
    "            yield scrapy.Request(url, callback=self.parse,proxy= self.proxy_ls[random.randint(0, len(self.proxy_ls)-1)] )\n",
    "    \n",
    "    def process_exception(self, request, exception, spider):   \n",
    "        if isinstance(exception, TimeoutError) or isinstance(exception, TCPTimedOutError): \n",
    "            # time.sleep(10)\n",
    "            return self._retry(request, exception, spider)\n",
    "    \n",
    "    def parse(self, response):\n",
    "        title = response.xpath('//title/text()').get()\n",
    "        subtitle = response.xpath('/html/body/div[4]/div/div[2]/div/div[2]/div/div[2]/div[1]/ol/li[2]/a/text()').get() # ::text\n",
    "        body = response.css('div.avisoContenido article div#detalleAviso div#tituloDetalleAviso + div#cuerpoDetalleAviso p::text').get()\n",
    "        \n",
    "        print(next(gen),subtitle,end=\"\\r\")\n",
    "\n",
    "\n",
    "        yield {\n",
    "                'title': title,\n",
    "                'subtitle': subtitle,\n",
    "                'body': body\n",
    "            } \n",
    "\n",
    "@wait_for(10)\n",
    "def run_spider():\n",
    "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(QuotesSpider)\n",
    "    return d\n",
    "run_spider()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603fe6b7-6c83-4fee-bab4-9320c92f78c3",
   "metadata": {},
   "source": [
    "# Rotating Proxies II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1a022597-2e55-4451-90a8-3cd2bcc6de43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 CITACIONES Y NOTIFICACIONES. CONCURSOS Y QUIEBRAS. OTROS\r"
     ]
    }
   ],
   "source": [
    "ls = '103.30.182.116:80,109.236.44.178:8080,111.225.152.56:8089,111.225.152.70:8089,111225153100:8089,114.106.173.32:8089,116197132168:8989,117.54.114.101:80,119.76.142.206:8080,123.182.58.135:8089,159.203.61.169:8080,164.90.183.34:80,183.165.250.4:8089,198.44.188.224:45787,221.225.81.91:3128,34.102.16.169:8585,34.106.65.11:8585,35.228.251.0:8080,45175237194:999,45.92.108.112:80,58234116197:8193,62.89.9.10:8080,94130237161:8080,102.0.0.118:32650,105.16.115.202:80,113.53.53.7:8080,134.209.29.120:3128,138.68.60.8:8080'.split(',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a196130e-3496-44a3-8060-6a6ee4e86a71",
   "metadata": {},
   "outputs": [
    {
     "ename": "TimeoutError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 76\u001b[0m\n\u001b[0;32m     74\u001b[0m     d \u001b[38;5;241m=\u001b[39m crawler\u001b[38;5;241m.\u001b[39mcrawl(QuotesSpider)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m d\n\u001b[1;32m---> 76\u001b[0m \u001b[43mrun_spider\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\crochet\\_eventloop.py:461\u001b[0m, in \u001b[0;36mEventLoop.wait_for.<locals>.decorator.<locals>.wrapper\u001b[1;34m(function, _, args, kwargs)\u001b[0m\n\u001b[0;32m    459\u001b[0m eventual_result \u001b[38;5;241m=\u001b[39m run()\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43meventual_result\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m:\n\u001b[0;32m    463\u001b[0m     eventual_result\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\crochet\\_eventloop.py:196\u001b[0m, in \u001b[0;36mEventualResult.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m threadable\u001b[38;5;241m.\u001b[39misInIOThread():\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEventualResult.wait() must not be run in the reactor thread.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 196\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Failure):\n\u001b[0;32m    198\u001b[0m     result\u001b[38;5;241m.\u001b[39mraiseException()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\llm\\lib\\site-packages\\crochet\\_eventloop.py:175\u001b[0m, in \u001b[0;36mEventualResult._result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# In Python 2.6 we can't rely on the return result of wait(), so we\u001b[39;00m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# have to check manually:\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_set\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result_retrieved \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "\u001b[1;31mTimeoutError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def infinite_sequence():\n",
    "    num = 1\n",
    "    while True:\n",
    "        yield num\n",
    "        num += 1\n",
    "gen = infinite_sequence()\n",
    "\n",
    "\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('boletin_resultado.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item\n",
    "    \n",
    "setup()\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    header_list = get_headers_list()\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'CONCURRENT_REQUESTS_PER_IP':20,\n",
    "        'COOKIES_ENABLED':True,\n",
    "        #'DOWNLOAD_DELAY' : 0.25,\n",
    "        # Example Scrapy settings\n",
    "        'DOWNLOAD_TIMEOUT' : 180,\n",
    "        \n",
    "        'DOWNLOADER_MIDDLEWARES' : {'rotating_proxies.middlewares.RotatingProxyMiddleware': 610,'rotating_proxies.middlewares.BanDetectionMiddleware': 620},\n",
    "        'ROTATING_PROXY_LIST'  : ['103.30.182.116:80', '109.236.44.178:8080', '111.225.152.56:8089', '111.225.152.70:8089', '111225153100:8089', '114.106.173.32:8089', '116197132168:8989', '117.54.114.101:80', '119.76.142.206:8080', '123.182.58.135:8089', '159.203.61.169:8080', '164.90.183.34:80', '183.165.250.4:8089', '198.44.188.224:45787', '221.225.81.91:3128', '34.102.16.169:8585', '34.106.65.11:8585', '35.228.251.0:8080', '45175237194:999', '45.92.108.112:80', '58234116197:8193', '62.89.9.10:8080', '94130237161:8080', '102.0.0.118:32650', '105.16.115.202:80', '113.53.53.7:8080', '134.209.29.120:3128', '138.68.60.8:8080'],\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'boletin_resultado.json'                        # Used for pipeline 2\n",
    "        \n",
    "        \n",
    "    }\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    def start_requests(self):\n",
    "        urls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A{(7-len(str(i)))*\"0\"}{i}/20230503' for i in np.arange(1,1000)]\n",
    "        for i, url in enumerate(urls):\n",
    "            yield scrapy.Request(url, callback=self.parse)#,proxy= self.proxy_ls[random.randint(0, len(self.proxy_ls)-1)] )\n",
    "    \n",
    "    def process_exception(self, request, exception, spider):   \n",
    "        if isinstance(exception, TimeoutError) or isinstance(exception, TCPTimedOutError): \n",
    "            # time.sleep(10)\n",
    "            return self._retry(request, exception, spider)\n",
    "    \n",
    "    def parse(self, response):\n",
    "        title = response.xpath('//title/text()').get()\n",
    "        subtitle = response.xpath('/html/body/div[4]/div/div[2]/div/div[2]/div/div[2]/div[1]/ol/li[2]/a/text()').get() # ::text\n",
    "        body = response.css('div.avisoContenido article div#detalleAviso div#tituloDetalleAviso + div#cuerpoDetalleAviso p::text').get()\n",
    "        \n",
    "        print(next(gen),subtitle,end=\"\\r\")\n",
    "\n",
    "\n",
    "        yield {\n",
    "                'title': title,\n",
    "                'subtitle': subtitle,\n",
    "                'body': body\n",
    "            } \n",
    "\n",
    "@wait_for(10)\n",
    "def run_spider():\n",
    "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(QuotesSpider)\n",
    "    return d\n",
    "run_spider()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b3a682e-f6a7-449e-bc01-58a193d364f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from random import randint\n",
    "\n",
    "SCRAPEOPS_API_KEY = '889b76ad-0bd8-4922-9f7b-596e077b305c'\n",
    "\n",
    "def get_headers_list(n=10):\n",
    "  response = requests.get(\n",
    "  url='https://headers.scrapeops.io/v1/browser-headers',\n",
    "  params={\n",
    "      'api_key': SCRAPEOPS_API_KEY,\n",
    "      'num_headers': n}\n",
    "  )\n",
    "  json_response = response.json()\n",
    "  return json_response.get('result', [])\n",
    "\n",
    "def get_random_header(header_list):\n",
    "  random_index = randint(0, len(header_list) - 1)\n",
    "  return header_list[random_index]\n",
    "\n",
    "\n",
    "header_list = get_headers_list()\n",
    "\n",
    "# url_list = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A{(7-len(str(i)))*\"0\"}{i}/20230503' for i in np.arange(1,3)]\n",
    "\n",
    "# for url in url_list:\n",
    "#   r = requests.get(url=url, headers=get_random_header(header_list))\n",
    "#   print(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f114cb-4af4-41d6-8ea6-2a4e11ecd428",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce6172a2-06dc-41b8-9ea2-50c87ae04572",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RESCATANDO A RYAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f3111f65-aff7-4c86-aac7-0b3b071dad21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 None\r"
     ]
    }
   ],
   "source": [
    "urls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A{(7-len(str(i)))*\"0\"}{i}/20230503' for i in np.arange(1,100)]\n",
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73963284-255f-4743-beda-2d7b1b4f255a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def infinite_sequence():\n",
    "    num = 1\n",
    "    while True:\n",
    "        yield num\n",
    "        num += 1\n",
    "gen = infinite_sequence()\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d460a0ff-f123-4221-b0db-e81a6184b424",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (956522938.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[117], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    [f'https://www.boletinoficial.gob.ar/seccion/segunda/202210'{(2-len(str(i)))*\"0\"}{i} for i in np.arange(1,30)]\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "[f'https://www.boletinoficial.gob.ar/seccion/segunda/202210'{(2-len(str(i)))*\"0\"}{i} for i in np.arange(1,30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b67a9-0e66-42e6-84c9-9763a5204a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A{(7-len(str(i)))*\"0\"}{i}/20230503' for i in np.arange(1,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41e846f9-9919-4ad7-ba97-12f65ceabded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infinite_sequence():\n",
    "    num = 1\n",
    "    while True:\n",
    "        yield num\n",
    "        num += 1\n",
    "gen = infinite_sequence()\n",
    "\n",
    "class JsonWriterPipeline(object):\n",
    "\n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('boletin_resultado.jl', 'w')\n",
    "\n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item\n",
    "    \n",
    "setup()\n",
    "class QuotesSpider(scrapy.Spider):\n",
    "    name = \"quotes\"\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        #'CONCURRENT_REQUESTS_PER_IP':0,\n",
    "        'COOKIES_ENABLED':True,\n",
    "        #'DOWNLOAD_DELAY' : 5,\n",
    "        # Example Scrapy settings\n",
    "        'DOWNLOAD_TIMEOUT' : 180,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWriterPipeline': 1}, # Used for pipeline 1\n",
    "        'FEED_FORMAT':'json',                                 # Used for pipeline 2\n",
    "        'FEED_URI': 'boletin_resultado.json'                        # Used for pipeline 2\n",
    "    }\n",
    "\n",
    "    def start_requests(self):\n",
    "        urls = [f'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A{(7-len(str(i)))*\"0\"}{i}/20230503' for i in np.arange(1,100)]\n",
    "        for i, url in enumerate(urls):\n",
    "            yield scrapy.Request(url, meta={'cookiejar': i}, callback=self.parse)\n",
    "\n",
    "    def process_exception(self, request, exception, spider):   \n",
    "        if isinstance(exception, TimeoutError) or isinstance(exception, TCPTimedOutError): \n",
    "            time.sleep(60)\n",
    "            return self._retry(request, exception, spider)\n",
    "    \n",
    "    def parse(self, response):\n",
    "        \n",
    "        title = response.xpath('//title/text()').get()\n",
    "        subtitle = response.xpath('/html/body/div[4]/div/div[2]/div/div[2]/div/div[2]/div[1]/ol/li[2]/a/text()').get() # ::text\n",
    "        body = response.css('div.avisoContenido article div#detalleAviso div#tituloDetalleAviso + div#cuerpoDetalleAviso p::text').get()\n",
    "        \n",
    "        \n",
    "        print(next(gen),subtitle,end=\"\\r\")\n",
    "\n",
    "\n",
    "\n",
    "        yield {\n",
    "                'title': title,\n",
    "                'subtitle': subtitle,\n",
    "                'body': body\n",
    "            } \n",
    "\n",
    "@wait_for(10)\n",
    "def run_spider():\n",
    "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(QuotesSpider)\n",
    "    return d\n",
    "run_spider()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
