{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8915f62d-7719-41d4-8b5e-1d6dd6383305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install virtualenv\n",
    "# pip install scrapy\n",
    "# pip install crochet\n",
    "# ! cd /2_LLMs\n",
    "# ! virtualenv venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935b0fb9-de12-427b-bb1d-3ad0b8335d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! scrapy\n",
    "# !scrapy startproject bookscraper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e0d8ed-9ed2-4a3d-9821-e93837d8a71b",
   "metadata": {},
   "source": [
    "Fuentes:\n",
    "    \n",
    "    \n",
    "    https://www.mikulskibartosz.name/how-to-scrape-a-single-web-page-using-scrapy-in-jupyter-notebook/\n",
    "    \n",
    "Data:\n",
    "\n",
    "    https://www.boletinoficial.gob.ar/detalleAviso/segunda/A0000001/20230503 (boletín digital)\n",
    "    https://www.boletinoficial.gob.ar/detalleAviso/segunda/H681119/19830527 (boletín impreso/pdf)\n",
    "    https://timeline.boletinoficial.gob.ar/ (búsqueda)\n",
    "    https://www.boletinoficial.gob.ar/busquedaAvanzada/segunda\n",
    "    \n",
    "    scrapping boletin oficial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12dc0532-5727-4be9-b3d4-76db9856bbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "# scrape webpage\n",
    "import scrapy\n",
    "from scrapy.crawler import CrawlerRunner\n",
    "# Reactor restart\n",
    "from crochet import setup, wait_for\n",
    "\n",
    "\n",
    "os.getcwd()\n",
    "os.chdir('C:\\\\Users\\\\juani\\\\Documents\\\\3_My_Jupiter_Notebooks\\\\5_Galicia\\\\2_LLMs\\\\venv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057769c4-d09d-483b-adc9-83744f7684c2",
   "metadata": {},
   "source": [
    "# CASO 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02dac8d2-6f5d-4542-8aed-e13be69d0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup()\n",
    "class QuotesToCsv(scrapy.Spider):\n",
    "    \"\"\"scrape first line of  quotes from `wikiquote` by \n",
    "    Maynard James Keenan and save to json file\"\"\"\n",
    "    name = \"MJKQuotesToCsv\"\n",
    "    start_urls = [\n",
    "        'https://en.wikiquote.org/wiki/Maynard_James_Keenan',\n",
    "    ]\n",
    "    custom_settings = {\n",
    "        'ITEM_PIPELINES': {\n",
    "            '__main__.ExtractFirstLine': 1\n",
    "        },\n",
    "        'FEEDS': {\n",
    "            'quotes.csv': {\n",
    "                'format': 'csv',\n",
    "                'overwrite': True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def parse(self, response):\n",
    "        \"\"\"parse data from urls\"\"\"\n",
    "        for quote in response.css('div.mw-parser-output > ul > li'):\n",
    "            yield {'quote': quote.extract()}\n",
    "\n",
    "\n",
    "class ExtractFirstLine(object):\n",
    "    def process_item(self, item, spider):\n",
    "        \"\"\"text processing\"\"\"\n",
    "        lines = dict(item)[\"quote\"].splitlines()\n",
    "        first_line = self.__remove_html_tags__(lines[0])\n",
    "\n",
    "        return {'quote': first_line}\n",
    "\n",
    "    def __remove_html_tags__(self, text):\n",
    "        \"\"\"remove html tags from string\"\"\"\n",
    "        html_tags = re.compile('<.*?>')\n",
    "        return re.sub(html_tags, '', text)\n",
    "\n",
    "@wait_for(10)\n",
    "def run_spider():\n",
    "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(QuotesToCsv)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc96c491-49c6-4fc3-afc6-0c58e3ae2a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_spider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b9d4e4-821c-44ca-9bce-8b4708030a1d",
   "metadata": {},
   "source": [
    "# CASO BOLETIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd12f0c5-ddfd-4d92-b5e7-c3b1c2062fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Deferred at 0x1eaadd86530>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BoletinSpider(scrapy.Spider):\n",
    "    name = \"boletin\"\n",
    "    start_urls = [\n",
    "        \"https://www.boletinoficial.gob.ar/detalleAviso/segunda/A1194898/20230503\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        item = {}        \n",
    "        item[\"title\"] = response.xpath('//title/text()').get()\n",
    "        item[\"css\"] = response.css('div.avisoContenido article div#detalleAviso div#tituloDetalleAviso + div#cuerpoDetalleAviso p::text').get()\n",
    "        \n",
    "        print('title',item[\"title\"])\n",
    "        print('+css',item[\"css\"])\n",
    "        \n",
    "        yield {\"content\": item}\n",
    "\n",
    "def run_spider_BoletinSpider():\n",
    "    \"\"\"run spider with BoletinSpider\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(BoletinSpider)\n",
    "    return d\n",
    "run_spider_BoletinSpider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfdcb81a-b7f2-4349-8aa8-64fea9bb8ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Deferred at 0x21782ff2aa0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scrapy\n",
    "\n",
    "class MySpider(scrapy.Spider):\n",
    "    name = \"my_spider\"\n",
    "    start_urls = []\n",
    "    \n",
    "    def start_requests(self):\n",
    "        base_url = \"https://www.boletinoficial.gob.ar/detalleAviso/segunda\"\n",
    "        a_values = [\"A1194898\", \"A1234567\", \"A9876543\"] # List of different values for A\n",
    "        b_values = [\"20230503\", \"20230430\", \"20230401\"] # List of different values for B\n",
    "        for a in a_values:\n",
    "            for b in b_values:\n",
    "                url = f\"{base_url}/{a}/{b}\"\n",
    "                yield scrapy.Request(url=url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        # Extract data from the response object\n",
    "        # For example:\n",
    "        content = response.css('div.avisoContenido article div#cuerpoDetalleAviso p::text').get()\n",
    "        yield {\"content\": content}\n",
    "        \n",
    "        \n",
    "def run_spider_BoletinSpider():\n",
    "    \"\"\"run spider with BoletinSpider\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(MySpider)\n",
    "    return d\n",
    "\n",
    "\n",
    "run_spider_BoletinSpider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a189dee-ea9e-4969-9473-5fc04906e985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\juani\\anaconda3\\envs\\llm\\lib\\site-packages\\scrapy\\utils\\request.py:232: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n"
     ]
    }
   ],
   "source": [
    "# Please adapt the following code written in python using the libraries scrapy and crochet in order to save to a csv the scraped content of the website:\n",
    "\n",
    "class BoletinSpider(scrapy.Spider):\n",
    "    name = \"boletin\"\n",
    "    start_urls = [\n",
    "        \"https://www.boletinoficial.gob.ar/detalleAviso/segunda/A1194898/20230503\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        item = {}        \n",
    "        title = response.xpath('//title/text()').get()\n",
    "        content = response.css('div.avisoContenido article div#detalleAviso div#tituloDetalleAviso + div#cuerpoDetalleAviso p::text').get()\n",
    "        # content = response.css('div.avisoContenido article div#cuerpoDetalleAviso p::text').get()\n",
    "        yield {\"title\": title, 'content':content}\n",
    "\n",
    "def run_spider_BoletinSpider():\n",
    "    \"\"\"run spider with BoletinSpider\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(BoletinSpider)\n",
    "    return d\n",
    "\n",
    "\n",
    "test = run_spider_BoletinSpider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bdc5ee0-e4fb-4159-993c-e5d74eb6c117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Deferred at 0x21ca875d330>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ea747d-8f15-40bd-b731-199a8e5431f1",
   "metadata": {},
   "source": [
    "# CASO BOLETIN CON OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b6b50b-2678-42c1-8321-d2f16af4982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup()\n",
    "class BoletinToCsv(scrapy.Spider):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    name = \"BoletinToCsv\"\n",
    "    start_urls = [\n",
    "        'https://www.boletinoficial.gob.ar/detalleAviso/segunda/A1194898/20230503',\n",
    "    ]\n",
    "    custom_settings = {\n",
    "        'ITEM_PIPELINES': {\n",
    "            '__main__.ExtractFirstLine': 1\n",
    "        },\n",
    "        'FEEDS': {\n",
    "            'quotes.csv': {\n",
    "                'format': 'csv',\n",
    "                'overwrite': True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def parse(self, response):\n",
    "        \"\"\"parse data from urls\"\"\"\n",
    "        item = {}\n",
    "        item[\"title\"] = response.xpath('//title/text()').get()\n",
    "        item[\"css\"] = response.css('div.avisoContenido article div#detalleAviso div#tituloDetalleAviso + div#cuerpoDetalleAviso p::text').get()\n",
    "        yield item\n",
    "\n",
    "\n",
    "class ExtractFirstLine(object):\n",
    "    def process_item(self, item, spider):\n",
    "        \"\"\"text processing\"\"\"\n",
    "        lines = dict(item)[\"quote\"].splitlines()\n",
    "        first_line = self.__remove_html_tags__(lines[0])\n",
    "\n",
    "        return {'quote': first_line}\n",
    "\n",
    "    def __remove_html_tags__(self, text):\n",
    "        \"\"\"remove html tags from string\"\"\"\n",
    "        html_tags = re.compile('<.*?>')\n",
    "        return re.sub(html_tags, '', text)\n",
    "\n",
    "@wait_for(10)\n",
    "def run_spider():\n",
    "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(QuotesToCsv)\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "class BoletinSpider(scrapy.Spider):\n",
    "    name = \"boletin\"\n",
    "    start_urls = [\n",
    "        \"https://www.boletinoficial.gob.ar/detalleAviso/segunda/A1194898/20230503\"\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        item = {}\n",
    "        # title = response.xpath('//title/text()').get()\n",
    "        item[\"title\"] = response.xpath('//title/text()').get()\n",
    "        # item[\"body\"] = response.xpath('//div[@class=\"avisoContenido\"]/article/div[@id=\"cuerpoDetalleAviso\"]/p/text()').get()\n",
    "        item[\"css\"] = response.css('div.avisoContenido article div#detalleAviso div#tituloDetalleAviso + div#cuerpoDetalleAviso p::text').get()\n",
    "\n",
    "        # item[\"body\"] = response.xpath('//div[@id=\"tituloDetalleAviso\"]').get()\n",
    "        # print(item[\"title\"])\n",
    "        print('title',item[\"title\"])\n",
    "        print('css',item[\"css\"])\n",
    "\n",
    "        # for k,v in item.items():\n",
    "        #     print(k,v)\n",
    "        \n",
    "        \n",
    "        # product = response.css(\"div.product_main\")\n",
    "        # item[\"title\"] = product.css(\"h1 ::text\").extract_first()\n",
    "        # item['category'] = response.xpath(\n",
    "        #     \"//ul[@class='breadcrumb']/li[@class='active']/preceding-sibling::li[1]/a/text()\"\n",
    "        # ).extract_first()\n",
    "        # item['description'] = response.xpath(\n",
    "        #     \"//div[@id='product_description']/following-sibling::p/text()\"\n",
    "        # ).extract_first()\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        return item\n",
    "def run_spider_BoletinSpider():\n",
    "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(BoletinSpider)\n",
    "    return d\n",
    "test = run_spider_BoletinSpider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e9a5c2-78a3-4d57-b9aa-875d60b955e9",
   "metadata": {},
   "source": [
    "# CASO 2 tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8304fece-cd60-4a1a-909c-8195310b227d",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup()\n",
    "\n",
    "class BooksSpider(scrapy.Spider):\n",
    "    name = 'books'\n",
    "\n",
    "    def start_requests(self):\n",
    "        url = 'https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'\n",
    "        yield scrapy.Request(url, callback=self.parse)\n",
    "\n",
    "    def parse(self, response):\n",
    "        item = {}\n",
    "        product = response.css(\"div.product_main\")\n",
    "        item[\"title\"] = product.css(\"h1 ::text\").extract_first()\n",
    "        item['category'] = response.xpath(\n",
    "            \"//ul[@class='breadcrumb']/li[@class='active']/preceding-sibling::li[1]/a/text()\"\n",
    "        ).extract_first()\n",
    "        item['description'] = response.xpath(\n",
    "            \"//div[@id='product_description']/following-sibling::p/text()\"\n",
    "        ).extract_first()\n",
    "        item['price'] = response.css('p.price_color ::text').extract_first()\n",
    "        yield item\n",
    "@wait_for(10)       \n",
    "def run_spider2():\n",
    "    \"\"\"run spider with MJKQuotesToCsv\"\"\"\n",
    "    crawler = CrawlerRunner()\n",
    "    d = crawler.crawl(BooksSpider)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "006c3e59-0439-4a6b-bfb6-f93ecb67792e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Request' object has no attribute 'css'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m product \u001b[38;5;241m=\u001b[39m  scrapy\u001b[38;5;241m.\u001b[39mRequest(url)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mproduct\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcss\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv.product_main\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Request' object has no attribute 'css'"
     ]
    }
   ],
   "source": [
    "url = 'https://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html'\n",
    "product =  scrapy.Request(url)\n",
    "product.css(\"div.product_main\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
